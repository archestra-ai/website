{
  "name": "any chat completions",
  "slug": "pyroprompts__any-chat-completions-mcp",
  "description": "MCP Server for using any LLM as a Tool",
  "readme": "# any-chat-completions-mcp MCP Server\n\n\nIntegrate Claude with Any OpenAI SDK Compatible Chat Completion API - OpenAI, Perplexity, Groq, xAI, PyroPrompts and more.\n\nThis implements the Model Context Protocol Server. Learn more: [https://modelcontextprotocol.io](https://modelcontextprotocol.io)\n\nThis is a TypeScript-based MCP server that implements an implementation into any OpenAI SDK Compatible Chat Completions API.\n\nIt has one tool, `chat` which relays a question to a configured AI Chat Provider.\n\n\n<a href=\"https://glama.ai/mcp/servers/nuksdrfb55\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/nuksdrfb55/badge\" /></a>\n\n[![smithery badge](https://smithery.ai/badge/any-chat-completions-mcp-server)](https://smithery.ai/server/any-chat-completions-mcp-server)\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\nnpm run watch\n```\n\n## Installation\n\nTo add OpenAI to Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\n\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\n\nYou can use it via `npx` in your Claude Desktop configuration like this:\n\n```json\n{\n  \"mcpServers\": {\n    \"chat-openai\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"@pyroprompts/any-chat-completions-mcp\"\n      ],\n      \"env\": {\n        \"AI_CHAT_KEY\": \"OPENAI_KEY\",\n        \"AI_CHAT_NAME\": \"OpenAI\",\n        \"AI_CHAT_MODEL\": \"gpt-4o\",\n        \"AI_CHAT_BASE_URL\": \"https://api.openai.com/v1\"\n      }\n    }\n  }\n}\n```\n\n\nOr, if you clone the repo, you can build and use in your Claude Desktop configuration like this:\n\n\n```json\n\n{\n  \"mcpServers\": {\n    \"chat-openai\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/path/to/any-chat-completions-mcp/build/index.js\"\n      ],\n      \"env\": {\n        \"AI_CHAT_KEY\": \"OPENAI_KEY\",\n        \"AI_CHAT_NAME\": \"OpenAI\",\n        \"AI_CHAT_MODEL\": \"gpt-4o\",\n        \"AI_CHAT_BASE_URL\": \"https://api.openai.com/v1\"\n      }\n    }\n  }\n}\n```\n\nYou can add multiple providers by referencing the same MCP server multiple times, but with different env arguments:\n\n```json\n\n{\n  \"mcpServers\": {\n    \"chat-pyroprompts\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/path/to/any-chat-completions-mcp/build/index.js\"\n      ],\n      \"env\": {\n        \"AI_CHAT_KEY\": \"PYROPROMPTS_KEY\",\n        \"AI_CHAT_NAME\": \"PyroPrompts\",\n        \"AI_CHAT_MODEL\": \"ash\",\n        \"AI_CHAT_BASE_URL\": \"https://api.pyroprompts.com/openaiv1\"\n      }\n    },\n    \"chat-perplexity\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/path/to/any-chat-completions-mcp/build/index.js\"\n      ],\n      \"env\": {\n        \"AI_CHAT_KEY\": \"PERPLEXITY_KEY\",\n        \"AI_CHAT_NAME\": \"Perplexity\",\n        \"AI_CHAT_MODEL\": \"sonar\",\n        \"AI_CHAT_BASE_URL\": \"https://api.perplexity.ai\"\n      }\n    },\n    \"chat-openai\": {\n      \"command\": \"node\",\n      \"args\": [\n        \"/path/to/any-chat-completions-mcp/build/index.js\"\n      ],\n      \"env\": {\n        \"AI_CHAT_KEY\": \"OPENAI_KEY\",\n        \"AI_CHAT_NAME\": \"OpenAI\",\n        \"AI_CHAT_MODEL\": \"gpt-4o\",\n        \"AI_CHAT_BASE_URL\": \"https://api.openai.com/v1\"\n      }\n    }\n  }\n}\n```\n\nWith these three, you'll see a tool for each in the Claude Desktop Home:\n\n![Claude Desktop Home with Chat Tools](img/claude_desktop_home.png)\n\nAnd then you can chat with other LLMs and it shows in chat like this:\n\n![Claude Chat with OpenAI](img/claude_chat_openai.png)\n\nOr, configure in [LibreChat](https://www.librechat.ai/) like:\n```yaml\n  chat-perplexity:\n    type: stdio\n    command: npx\n    args:\n      - -y\n      - @pyroprompts/any-chat-completions-mcp\n    env:\n      AI_CHAT_KEY: \"pplx-012345679\"\n      AI_CHAT_NAME: Perplexity\n      AI_CHAT_MODEL: sonar\n      AI_CHAT_BASE_URL: \"https://api.perplexity.ai\"\n      PATH: '/usr/local/bin:/usr/bin:/bin'\n````\n\nAnd it shows in LibreChat:\n\n![LibreChat with Perplexity Chat](img/librechat.png)\n\n\n\n\n### Installing via Smithery\n\nTo install Any OpenAI Compatible API Integrations for Claude Desktop automatically via [Smithery](https://smithery.ai/server/any-chat-completions-mcp-server):\n\n```bash\nnpx -y @smithery/cli install any-chat-completions-mcp-server --client claude\n```\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n\n### Acknowledgements\n\n- Obviously the modelcontextprotocol and Anthropic team for the MCP Specification and integration into Claude Desktop. [https://modelcontextprotocol.io/introduction](https://modelcontextprotocol.io/introduction)\n- [PyroPrompts](https://pyroprompts.com?ref=github-any-chat-completions-mcp) for sponsoring this project. Use code `CLAUDEANYCHAT` for 20 free automation credits on Pyroprompts.\n",
  "category": "AI Tools",
  "qualityScore": 60,
  "githubUrl": "https://github.com/pyroprompts/any-chat-completions-mcp",
  "programmingLanguage": "JavaScript",
  "gitHubOrg": "pyroprompts",
  "gitHubRepo": "any-chat-completions-mcp",
  "repositoryPath": null,
  "gh_stars": 139,
  "gh_contributors": 4,
  "gh_issues": 4,
  "gh_releases": true,
  "gh_ci_cd": false,
  "gh_latest_commit_hash": "20f715e85fe19917ff02cd8d7cfcd4667a52a146",
  "last_scraped_at": "2025-08-03T21:03:28.816Z",
  "implementing_tools": true,
  "implementing_prompts": false,
  "implementing_resources": false,
  "implementing_sampling": true,
  "implementing_roots": false,
  "implementing_logging": false,
  "implementing_stdio": true,
  "implementing_streamable_http": false,
  "implementing_oauth2": false,
  "rawDependencies": "=== package.json ===\n{\n  \"name\": \"@pyroprompts/any-chat-completions-mcp\",\n  \"version\": \"0.1.1\",\n  \"description\": \"A Model Context Protocol server for integrating with any OpenAI SDK compatible Chat Completion API\",\n  \"type\": \"module\",\n  \"bin\": {\n    \"any-chat-completions-mcp\": \"build/cli.js\"\n  },\n  \"files\": [\n    \"build\"\n  ],\n  \"scripts\": {\n    \"build\": \"tsc && node -e \\\"require('fs').chmodSync('build/index.js', '755'); require('fs').chmodSync('build/cli.js', '755')\\\"\",\n    \"prepare\": \"npm run build\",\n    \"watch\": \"tsc --watch\",\n    \"inspector\": \"npx @modelcontextprotocol/inspector build/index.js\",\n    \"clean\": \"rm -rf build\",\n    \"npm-publish\": \"npm run clean && npm run build && npm publish --access=public\",\n    \"start\": \"node build/cli.js\"\n  },\n  \"dependencies\": {\n    \"@modelcontextprotocol/sdk\": \"0.6.0\",\n    \"dotenv\": \"^16.4.5\",\n    \"openai\": \"^4.73.1\"\n  },\n  \"devDependencies\": {\n    \"@types/node\": \"^20.11.24\",\n    \"typescript\": \"^5.3.3\"\n  },\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"git+https://github.com/pyroprompts/any-chat-completions-mcp.git\"\n  },\n  \"keywords\": [\n    \"claude\",\n    \"openai\",\n    \"mcp\",\n    \"model-context-protocol\",\n    \"ai\",\n    \"chat\",\n    \"llm\"\n  ],\n  \"author\": \"PyroPrompts\",\n  \"license\": \"MIT\",\n  \"engines\": {\n    \"node\": \">=18\"\n  }\n}\n",
  "evaluation_model": "gemini-2.5-flash",
  "configForClients": {
    "mcpServers": {
      "pyroprompts-any-chat-completions-mcp-openai-npx": {
        "command": "npx",
        "args": ["@pyroprompts/any-chat-completions-mcp"],
        "env": {
          "AI_CHAT_KEY": "OPENAI_KEY",
          "AI_CHAT_NAME": "OpenAI",
          "AI_CHAT_MODEL": "gpt-4o",
          "AI_CHAT_BASE_URL": "https://api.openai.com/v1"
        }
      },
      "any-chat-completions-mcp-openai-local": {
        "command": "node",
        "args": ["/path/to/any-chat-completions-mcp/build/index.js"],
        "env": {
          "AI_CHAT_KEY": "OPENAI_KEY",
          "AI_CHAT_NAME": "OpenAI",
          "AI_CHAT_MODEL": "gpt-4o",
          "AI_CHAT_BASE_URL": "https://api.openai.com/v1"
        }
      },
      "any-chat-completions-mcp-pyroprompts-local": {
        "command": "node",
        "args": ["/path/to/any-chat-completions-mcp/build/index.js"],
        "env": {
          "AI_CHAT_KEY": "PYROPROMPTS_KEY",
          "AI_CHAT_NAME": "PyroPrompts",
          "AI_CHAT_MODEL": "ash",
          "AI_CHAT_BASE_URL": "https://api.pyroprompts.com/openaiv1"
        }
      },
      "any-chat-completions-mcp-perplexity-local": {
        "command": "node",
        "args": ["/path/to/any-chat-completions-mcp/build/index.js"],
        "env": {
          "AI_CHAT_KEY": "PERPLEXITY_KEY",
          "AI_CHAT_NAME": "Perplexity",
          "AI_CHAT_MODEL": "sonar",
          "AI_CHAT_BASE_URL": "https://api.perplexity.ai"
        }
      },
      "pyroprompts-any-chat-completions-mcp-perplexity-stdio": {
        "command": "npx",
        "args": ["-y", "@pyroprompts/any-chat-completions-mcp"],
        "env": {
          "AI_CHAT_KEY": "pplx-012345679",
          "AI_CHAT_NAME": "Perplexity",
          "AI_CHAT_MODEL": "sonar",
          "AI_CHAT_BASE_URL": "https://api.perplexity.ai",
          "PATH": "/usr/local/bin:/usr/bin:/bin"
        }
      }
    }
  },
  "configForArchestra": {
    "command": "npx",
    "args": ["-y", "@pyroprompts/any-chat-completions-mcp"],
    "env": {
      "server-basic": "",
      "server-configured": "",
      "server-docker": ""
    },
    "transport": "stdio",
    "oauth": {}
  },
  "dependencies": [
    {
      "importance": 10,
      "name": "@modelcontextprotocol/sdk"
    },
    {
      "importance": 5,
      "name": "dotenv"
    },
    {
      "importance": 9,
      "name": "openai"
    }
  ]
}
