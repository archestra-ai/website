{
  "dxt_version": "0.1.0",
  "name": "janreges__ai-distiller",
  "display_name": "ai-distiller",
  "version": "1.0.0",
  "description": "AI Distiller is ultra‚Äëfast, open‚Äësource tool for intelligently extracting only the essential public APIs, types, and structure from large codebases. Compresses 90‚Äì98% of code into AI‚Äëfriendly context, integrates via CLI or MCP, supports 12+ languages, and AI prompt workflows for cleaner, cost‚Äëeffective AI development.",
  "author": {
    "name": "janreges"
  },
  "server": {
    "type": "node",
    "entry_point": "index.js",
    "mcp_config": {
      "command": "npx",
      "args": ["-y", "@janreges/ai-distiller-mcp"],
      "env": {}
    }
  },
  "tools": [],
  "prompts": [],
  "keywords": [],
  "user_config": {},
  "readme": "# AI Distiller (`aid`)\n\n> **Note:** This is the very first version of this tool. We would be very grateful for any feedback in the form of a discussion or by creating an issue on [GitHub](https://github.com/janreges/ai-distiller/issues). Thank you\\!\n\nüöÄ **MCP Server Available**: Install the Model Context Protocol server for AI Distiller from NPM: [`@janreges/ai-distiller-mcp`](https://www.npmjs.com/package/@janreges/ai-distiller-mcp) - seamlessly integrate with Claude, Cursor, and other MCP-compatible AI tools!\n\n<p align=\"center\">\n  <img src=\"docs/assets/aid-mascot-300.png\" alt=\"AI Distiller (aid) Mascot\" width=\"200\">\n</p>\n\n<p align=\"center\">\n  <img src=\"https://img.shields.io/badge/Languages-12+-blue\" alt=\"12+ Languages\">\n  <img src=\"https://img.shields.io/badge/Performance-5k+_files/sec-green\" alt=\"Performance\">\n  <img src=\"https://img.shields.io/badge/Compression-90%25+-orange\" alt=\"Compression\">\n  <img src=\"https://img.shields.io/badge/Tests-1211_passed-purple\" alt=\"Tests\">\n</p\n\n\n## **ü§î Why AI Distiller?**\n\nDo you work with large-scale projects that have thousands of files and functions? Do you struggle with AI tools like Claude Code, Gemini, Copilot, or Cursor frequently \"hallucinating\" and generating code that looks correct at first glance but is actually incompatible with your project?\n\n**The problem is context.** AI models have a limited context window and cannot comprehend your entire codebase. Instead, AI agents search files, \"grep\" for keywords, look at a few lines before and after the found term, and try (often, but not always) to guess the interface of your classes and functions. The result? Code full of errors that guesses parameters, returns incorrect data types, and ignores the existing architecture. If you are a sophisticated user of AI agents (vibe coder), you know that you can help yourself by instructing the AI ‚Äã‚Äãagent to consistently write and run tests, using static code analysis, pre-commit hooks, etc. - the AI ‚Äã‚Äãagent will usually fix the code itself, but in the meantime it will take 20 steps and 5 minutes. On the other hand, it must be admitted that if you pay for each AI request (and large context is an expensive factor) and are not \"playing for time\", you may not mind this limited context approach.\n\n**AI Distiller (or `aid` for short) helps solve this problem.** Its main function is code \"distillation\" ‚Äì a process where it extracts only the most essential information from the entire project (ideally from the main source folder, or a specific module subdirectory for extremely large projects) that the AI needs to write code correctly on the first try. This distillation usually generates a context that is only 5-20% of the original source code volume, allowing AI tools to include it in their context. As a result, the AI uses the existing code exactly as it was designed, not by trial and error.\n\nVery simply, it can be said that `aid`, within the distillation process, will leave only the public parts of the interface, input and output data types, but in the default state it will discard method implementations and non-public structures. But everything is configurable via [CLI Options](#-complete-cli-reference).\n\n## Table of Contents\n\n- [ü§î Why AI Distiller?](#-why-ai-distiller)\n- [‚ú® Key Features](#-key-features)\n- [üéØ How It Works](#-how-it-works)\n- [üîó Dependency-Aware Distillation](#-dependency-aware-distillation)\n- [üöÄ Quick Start](#-quick-start)\n  - [One-Line Installation](#one-line-installation)\n  - [Basic Usage](#basic-usage)\n- [üìñ Example Output](#-example-output)\n- [üìñ Guides & Examples](#-guides--examples)\n  - [Deep Code Analysis Prompt Generation](#deep-code-analysis-prompt-generation)\n  - [ü§ñ Use with Claude Desktop (MCP)](#-use-with-claude-desktop-mcp)\n- [üìñ Complete CLI Reference](#-complete-cli-reference)\n- [üõ†Ô∏è Advanced Usage](#-advanced-usage)\n  - [üö´ Ignoring Files with .aidignore](#-ignoring-files-with-aidignore)\n  - [üéØ Git History Analysis Mode](#-git-history-analysis-mode)\n- [‚ö†Ô∏è Limitations](#-limitations)\n- [üîí Security Considerations](#-security-considerations)\n- [‚ùì FAQ](#-faq)\n- [ü§ù Contributing](#-contributing)\n- [üìÑ License](#-license)\n- [üôè Acknowledgments](#-acknowledgments)\n\n## **‚ú® Key Features**\n\n| Feature | Description | \n| ------- | ----------- |\n| üöÄ Extreme Speed | Processes tens of megabytes of code in hundreds of milliseconds. By default, it uses 80% of available CPU cores, but can be configured, e.g., with `--workers=1` to use only a single CPU core. |  \n| üß† Intelligent Distillation | Understands 12+ programming languages and extracts only public APIs (methods, properties, types). |  \n| ‚öôÔ∏è High Configurability | Allows including private, protected, and internal members, implementation, or comments. |  \n| ü§ñ AI Prompt Generation | Generates ready-to-use prompts with distilled code for AI analysis. The tool creates files with prompts that AI agents can then execute for security audits, refactoring, etc. See `--ai-action` switch. |  \n| üìã Analysis Automation | Creates a complete checklist and directory structure for AI agents, who can then systematically analyze the entire project. See the flow-for-\\* actions for the `--ai-action` switch. |  \n| üìú Git Analysis | Processes commit history and prepares data for in-depth analysis of development quality and team dynamics. |  \n| üíª Multi-platform | A single binary file with no dependencies for Windows, Linux, and macOS (x64 & ARM). |  \n| üîå Integration via MCP | Can be integrated into tools like Claude Code, VS Code, Cursor, Windsurf and others thanks to the included MCP server. |\n\n### üéØ Intelligent Filtering\n \nControl exactly what to include with our new granular flag system:\n\n**Visibility Control**:\n- `--public=1` (default) - Include public members\n- `--protected=0` (default) - Exclude protected members\n- `--internal=0` (default) - Exclude internal/package-private\n- `--private=0` (default) - Exclude private members\n\n**Content Control**:\n- `--comments=0` (default) - Exclude comments\n- `--docstrings=1` (default) - Include documentation\n- `--implementation=0` (default) - Exclude function/methods bodies\n- `--imports=1` (default) - Include import/use statements\n\n**Default behavior**: Shows only public API signatures with basic documentation - perfect for AI understanding while maintaining maximum compression.\n\n### ü§ñ AI-Powered Analysis Prompt Generation\n\nAI Distiller generates specialized prompts combined with distilled code for AI-driven analysis:\n\n- **`--ai-action=flow-for-deep-file-to-file-analysis`** - Generates task lists and prompts for systematic file-by-file analysis\n- **`--ai-action=flow-for-multi-file-docs`** - Creates documentation workflow prompts with code structure\n- **Output to files** - Prompts are saved to `.aid/` directory (or use `--stdout` for small codebases)\n- **Ready for AI execution** - Generated files contain both the analysis prompt and distilled code\n- **AI agent instructions** - Output includes guidance for AI agents to read and process the generated files\n- **Gemini advantage** - 1M token context window perfect for larger codebase analysis\n\n**Note**: AI Distiller doesn't perform the analysis itself - it prepares optimized prompts that AI agents (Claude, Gemini, ChatGPT) then execute. Users often need to explicitly ask their AI agent to process the generated file or copy its contents to web-based AI tools.\n\n### üìù Multiple Output Formats\n- **Text** (`--format text`) - Ultra-compact for AI consumption (default)\n- **Markdown** (`--format md`) - Clean, structured Markdown\n- **JSON Structured** (`--format json-structured`) - Rich semantic data for tools\n- **JSONL** (`--format jsonl`) - Streaming format\n- **XML** (`--format xml`) - Legacy system compatible\n\n### üìä Smart Summary Output\n\nAfter each distillation, AI Distiller displays a summary showing compression efficiency and processing speed:\n\n```bash\n# Default: Visual progress bar for interactive terminals (green dots = saved, red dots = remaining)\n‚ú® Distilled 970 files [‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 98% (10M ‚Üí 256K) in 231ms üí∞ ~2.4M tokens saved (~64k remaining)\n\n# Choose your preferred format with --summary-type\naid ./src --summary-type=stock-ticker\nüìä AID 97.6% ‚ñ≤ ‚îÇ SIZE: 10M‚Üí256K ‚îÇ TIME: 231ms ‚îÇ EST: ~2.4M tokens saved\n\n# JSON output\naid ./src --summary-type=json\n\n{\n  \"original_bytes\": 70020,\n  \"distilled_bytes\": 8244,\n  \"savings_pct\": 88.22622107969151,\n  \"duration_ms\": 6,\n  \"tokens_before\": 17505,\n  \"tokens_after\": 2061,\n  \"tokens_saved\": 15444,\n  \"token_savings_pct\": 88.22622107969151,\n  \"file_count\": 9,\n  \"output_path\": \"/home/user/project/.aid/aid.processor.txt\",\n  \"tokenizer\": \"cl100k_base\"\n}\n```\n\n**Available formats:**\n- `visual-progress-bar` (default) - Shows compression as a progress bar\n- `stock-ticker` - Compact stock market style display\n- `speedometer-dashboard` - Multi-line dashboard with metrics\n- `minimalist-sparkline` - Single line with all essential info\n- `ci-friendly` - Clean format for CI/CD pipelines\n- `json` - Machine-readable JSON output\n- `off` - Disable summary output\n\nUse `--no-emoji` to remove emojis from any format.\n\n### üìÅ Smart Project Root Detection\n\nAI Distiller automatically detects your project root and centralizes all outputs in a `.aid/` directory:\n\n- **Automatic detection**: Searches upward for `.aidrc`, `go.mod`, `package.json`, `.git`, etc.\n- **Consistent location**: All outputs go to `<project-root>/.aid/` regardless of where you run `aid`\n- **Cache management**: MCP cache stored in `.aid/cache/` for better organization\n- **Easy cleanup**: Add `.aid/` to `.gitignore` to keep outputs out of version control\n\n**Detection priority:**\n1. **`.aidrc` file** - Create this empty file to explicitly mark your project root\n2. **Language markers** - `go.mod`, `package.json`, `pyproject.toml`, etc.\n3. **Version control** - `.git` directory\n4. **Environment variable** - `AID_PROJECT_ROOT` (fallback if no markers found)\n5. **Current directory** - Final fallback with warning\n\n```bash\n# Mark a specific directory as project root (recommended)\ntouch /my/project/.aidrc\n\n# Run from anywhere in your project - outputs always go to project root\ncd deep/nested/directory\naid ../../../src  # Output: <project-root>/.aid/aid.src.txt\n\n# Use environment variable as fallback (useful for CI/CD)\nAID_PROJECT_ROOT=/build/workspace aid src/\n```\n\n### üåç Language Support\nCurrently supports 12 languages via tree-sitter:\n- **Full Support**: Python, Go, JavaScript, PHP, Ruby\n- **Beta**: TypeScript, Java, C#, Rust, Kotlin, Swift, C++\n- **Coming Soon**: Zig, Scala, Clojure\n\n#### Language-Specific Documentation:\n- [C++](docs/lang/cpp.md) - C++11/14/17/20 support with templates, namespaces, modern features\n- [C#](docs/lang/csharp.md) - Complete C# 12 support with records, nullable reference types, pattern matching\n- [Go](docs/lang/go.md) - Full Go support with interfaces, goroutines, generics (1.18+)\n- [Java](docs/lang/java.md) - Java 8-21 support with records, sealed classes, pattern matching\n- [JavaScript](docs/lang/javascript.md) - ES6+ support with classes, modules, async/await\n- [Kotlin](docs/lang/kotlin.md) - Kotlin 1.x support with coroutines, data classes, sealed classes\n- [PHP](docs/lang/php.md) - PHP 7.4+ with PHP 8.x features (attributes, union types, enums)\n- [Python](docs/lang/python.md) - Full Python 3.x support with type hints, async/await, decorators\n- [Ruby](docs/lang/ruby.md) - Ruby 2.x/3.x support with blocks, modules, metaprogramming\n- [Rust](docs/lang/rust.md) - Rust 2018/2021 editions with traits, lifetimes, async\n- [Swift](docs/lang/swift.md) - Swift 5.x support with protocols, extensions, property wrappers\n- [TypeScript](docs/lang/typescript.md) - TypeScript 4.x/5.x with generics, decorators, type system\n\n## üéØ How It Works\n\n1. **Scans** your codebase recursively for supported file types (10+ languages)\n2. **Parses** each file using language-specific tree-sitter parsers (all bundled, no dependencies)\n3. **Extracts** only what you need: public APIs, type signatures, class hierarchies\n4. **Outputs** in your preferred format: compact text, markdown, or structured JSON\n\nAll tree-sitter grammars are compiled into the `aid` binary - zero external dependencies!\n\n## üîó Dependency-Aware Distillation\n\n**Advanced Feature**: AI Distiller includes dependency-aware distillation that analyzes call graphs across files and includes only the code that is actually used from your codebase. This creates focused distillations for deep code analysis by following function/method calls across multiple files.\n\n> üí° **New to dependency analysis?** This feature traces which functions actually call each other in your code, creating a minimal context that includes only the relevant parts. Perfect for AI tools that need to understand code relationships without processing entire files.\n\n### üéØ How Dependency-Aware Analysis Works\n\nInstead of including entire files, dependency-aware distillation:\n1. **Identifies entry points** (main functions, exported APIs)\n2. **Traces function calls** across file boundaries\n3. **Builds call graphs** to understand dependencies\n4. **Includes only used code** - functions that are actually called\n5. **Filters out unused code** - dead code elimination for AI context\n\n```bash\n# Basic dependency analysis\naid main.py --dependency-aware\n\n# Control analysis depth\naid main.py --dependency-aware --max-depth=2\n\n# Include implementations for deeper analysis\naid main.py --dependency-aware --implementation=1 --max-depth=3\n```\n\n### üìä Language Support Quality\n\nWe've worked extensively to make dependency-aware distillation as reliable as possible across different programming languages. However, the complexity varies significantly between languages, and we want to be transparent about the current state:\n\n| Language | Support Level | Cross-File Analysis | Intra-File Calls | Performance | Notes |\n|----------|---------------|--------------------|--------------------|-------------|-------|\n| **Python** | üü¢ **Very Good** | ‚úÖ Full | ‚úÖ Complete | ~37ms | Package imports, all call patterns |\n| **JavaScript** | üü¢ **Very Good** | ‚úÖ Full | ‚úÖ Complete | ~38ms | CommonJS & ES6 modules |\n| **Go** | üü¢ **Very Good** | ‚úÖ Full | ‚úÖ Complete | ~37ms | Package system integration |\n| **Rust** | üü¢ **Very Good** | ‚úÖ Full | ‚úÖ Complete | ~36ms | Crate system, proper filtering |\n| **Java** | üü¢ **Very Good** | ‚úÖ Full | ‚úÖ Complete | ~41ms | Package imports, static methods |\n| **Swift** | üü¢ **Very Good** | ‚úÖ Full | ‚úÖ Complete | ~37ms | Class and static method detection |\n| **PHP** | üü¢ **Very Good** | ‚úÖ Full | ‚úÖ Complete | ~37ms | Include/require resolution |\n| **Ruby** | üü¢ **Very Good** | ‚úÖ Full | ‚úÖ Complete | ~40ms | Module system, all call patterns |\n| **TypeScript** | üü° **Limited** | ‚ùå Issues | ‚ùå Issues | N/A | Language processor limitations |\n| **C#** | üü° **Limited** | ‚ùå Issues | ‚ùå Issues | N/A | Language processor limitations |\n| **C++** | üü° **Limited** | ‚ùå Issues | ‚ùå Issues | N/A | Language processor limitations |\n| **Kotlin** | üü† **Good** | ‚úÖ Partial | ‚ö†Ô∏è Basic | ~45ms | Companion objects, some edge cases |\n\n**Legend:**\n- üü¢ **Very Good**: Production-ready, handles complex scenarios reliably\n- üü† **Good**: Solid functionality with minor limitations\n- üü° **Limited**: Basic functionality, parsing capabilities may be limited\n- ‚úÖ **Full**: Complete cross-file dependency tracing\n- ‚ö†Ô∏è **Basic**: Simple scenarios work well, complex patterns may be limited\n- ‚ùå **Issues**: Functionality is significantly limited\n\n### üöÄ Performance Characteristics\n\n**Very Good Performance** (8 languages):\n- **Processing Time**: 36-41ms consistently\n- **Compression**: 65-72% size reduction\n- **Scalability**: Handles projects up to 10 files efficiently\n- **Memory Usage**: Minimal, no hanging or timeout issues\n\n**Areas for Enhancement**:\n- **Large Projects**: Performance may be limited with 50+ files\n- **Language Processors**: C#, C++, TypeScript have fundamental limitations  \n- **Complex Call Patterns**: Advanced metaprogramming patterns may be limited\n\n### üí° When to Use Dependency-Aware Analysis\n\n**Perfect for:**\n- üéØ **Impact Analysis** - Understand what code is affected by changes\n- üîç **Code Navigation** - Follow execution flows across multiple files\n- üé™ **Focused Context** - Get only relevant code for AI assistants\n- üìö **Legacy Understanding** - Trace through complex codebases systematically\n- üîß **API Analysis** - See which methods are actually called vs. just defined\n\n**Best Practices:**\n```bash\n# Start with small depth for quick overview\naid main.py --dependency-aware --max-depth=1\n\n# Increase depth for comprehensive analysis\naid main.py --dependency-aware --max-depth=2 --implementation=1\n\n# Use with specific languages known to work well\naid src/ --dependency-aware --include=\"*.py,*.js,*.go\"\n```\n\n### üöÄ Transform Massive Codebases Into AI-Friendly Context\n\n> **The Problem**: Modern codebases contain thousands of files with millions of lines. But for AI to understand your code architecture, suggest improvements, or help with development, it doesn't need to see every implementation detail - it needs the **structure and public interfaces**.\n\n> **The Solution**: AI Distiller extracts only what matters - public APIs, types, and signatures - reducing codebase size by 90-98% while preserving all essential information for AI comprehension.\n\n<table>\n<tr>\n<th align=\"left\">Project</th>\n<th align=\"center\">Files</th>\n<th align=\"right\">Original Tokens</th>\n<th align=\"right\">Distilled Tokens</th>\n<th align=\"center\">Fits in Context<sup>1</sup></th>\n<th align=\"center\">Speed<sup>2</sup></th>\n</tr>\n<tr>\n<td>‚öõÔ∏è <code>react</code></td>\n<td align=\"center\">1,781</td>\n<td align=\"right\">~5.5M</td>\n<td align=\"right\"><strong>250K</strong> (-95%)</td>\n<td align=\"center\">‚úÖ Gemini<sup>3</sup></td>\n<td align=\"center\">2,875 files/s</td>\n</tr>\n<tr>\n<td>üé® <code>vscode</code></td>\n<td align=\"center\">4,768</td>\n<td align=\"right\">~22.5M</td>\n<td align=\"right\"><strong>2M</strong> (-91%)</td>\n<td align=\"center\">‚ö†Ô∏è Needs chunking</td>\n<td align=\"center\">5,072 files/s</td>\n</tr>\n<tr>\n<td>üêç <code>django</code></td>\n<td align=\"center\">970</td>\n<td align=\"right\">~10M</td>\n<td align=\"right\"><strong>256K</strong> (-97%)</td>\n<td align=\"center\">‚úÖ Gemini<sup>3</sup></td>\n<td align=\"center\">4,199 files/s</td>\n</tr>\n<tr>\n<td>üì¶ <code>prometheus</code></td>\n<td align=\"center\">685</td>\n<td align=\"right\">~8.5M</td>\n<td align=\"right\"><strong>154K</strong> (-98%)</td>\n<td align=\"center\">‚úÖ Claude/Gemini</td>\n<td align=\"center\">3,071 files/s</td>\n</tr>\n<tr>\n<td>ü¶Ä <code>rust-analyzer</code></td>\n<td align=\"center\">1,275</td>\n<td align=\"right\">~5.5M</td>\n<td align=\"right\"><strong>172K</strong> (-97%)</td>\n<td align=\"center\">‚úÖ Claude/Gemini</td>\n<td align=\"center\">10,451 files/s</td>\n</tr>\n<tr>\n<td>üöÄ <code>astro</code></td>\n<td align=\"center\">1,058</td>\n<td align=\"right\">~10.5M</td>\n<td align=\"right\"><strong>149K</strong> (-99%)</td>\n<td align=\"center\">‚úÖ Claude/Gemini</td>\n<td align=\"center\">5,212 files/s</td>\n</tr>\n<tr>\n<td>üíé <code>rails</code></td>\n<td align=\"center\">394</td>\n<td align=\"right\">~1M</td>\n<td align=\"right\"><strong>104K</strong> (-90%)</td>\n<td align=\"center\">‚úÖ ChatGPT-4o</td>\n<td align=\"center\">4,864 files/s</td>\n</tr>\n<tr>\n<td>üêò <code>laravel</code></td>\n<td align=\"center\">1,443</td>\n<td align=\"right\">~3M</td>\n<td align=\"right\"><strong>238K</strong> (-92%)</td>\n<td align=\"center\">‚úÖ Gemini<sup>3</sup></td>\n<td align=\"center\">4,613 files/s</td>\n</tr>\n<tr>\n<td>‚ö° <code>nestjs</code></td>\n<td align=\"center\">802</td>\n<td align=\"right\">~1.5M</td>\n<td align=\"right\"><strong>107K</strong> (-93%)</td>\n<td align=\"center\">‚úÖ ChatGPT-4o</td>\n<td align=\"center\">8,813 files/s</td>\n</tr>\n<tr>\n<td>üëª <code>ghost</code></td>\n<td align=\"center\">2,184</td>\n<td align=\"right\">~8M</td>\n<td align=\"right\"><strong>235K</strong> (-97%)</td>\n<td align=\"center\">‚úÖ Gemini<sup>3</sup></td>\n<td align=\"center\">4,719 files/s</td>\n</tr>\n</table>\n\n<sub><sup>1</sup> Context windows: ChatGPT-4o (128K), Claude (200K), Gemini (1M). ‚úÖ = fits completely, ‚ö†Ô∏è = needs splitting</sub><br>\n<sub><sup>2</sup> Processing speed with 12 parallel workers on AMD Ryzen 7945HX. Use `-w 1` for serial mode or `-w N` for custom workers.</sub><br>\n<sub><sup>3</sup> These frameworks exceed 200K tokens and work only with Gemini due to its larger 1M token context window.</sub>\n\n### üéØ Why This Matters for AI-Assisted Development\n\n**Large codebases are overwhelming for AI models.** A typical web framework like Django has ~10 million tokens of source code. Even with Claude's 200K context window, you'd need to split it into 50+ chunks, losing coherence and relationships between components.\n\n**But here's the good news**: Most real-world projects that teams have invested hundreds to thousands of hours developing are much smaller. Thanks to AI Distiller, the vast majority of typical business applications, SaaS products, and internal tools can fit entirely within AI context windows, enabling unprecedented AI assistance quality.\n\n### ‚ö†Ô∏è The Hidden Problem with AI Coding Tools\n\n**Most AI agents and IDEs are \"context misers\"** - they try to save tokens at the expense of actual codebase knowledge. They rely on:\n- üîç **Grep/search** to find relevant code snippets\n- üìÑ **Limited context** showing only 10-50 lines around matches  \n- üé≤ **Guessing interfaces** based on partial information\n\n**This is why AI-generated code often fails on first attempts** - the AI is literally guessing method signatures, parameter types, and return values because it can't see the full picture.\n\n**AI Distiller changes the game** by giving AI complete knowledge of:\n- ‚úÖ **Exact interfaces** of all classes, methods, and functions\n- ‚úÖ **All parameter types** and their expected values\n- ‚úÖ **Return types** and data structures\n- ‚úÖ **Full inheritance hierarchies** and relationships\n\nInstead of playing \"code roulette\", AI can now write correct code from the start.\n\n**Result**: Django's 10M tokens compress to just 256K tokens - suddenly the **entire framework fits in a single AI conversation**, leading to:\n- üéØ **More accurate suggestions** - AI sees all available APIs at once\n- üöÄ **Less hallucination** - No more inventing methods that don't exist\n- üí° **Better architecture advice** - AI understands the full system design\n- ‚ö° **Faster development** - Especially for \"vibe coding\" with AI assistance\n- üí∞ **40x cost reduction** - Pay for 256K tokens instead of 10M on API calls\n\n### üîß Flexible for Different Use Cases\n\n```bash\n# Process entire codebase (default: public APIs only)\naid ./my-project\n\n# Process specific directory or module\naid ./my-project/src/auth\naid ./my-project/src/api\n\n# Process a directory\naid ./my-project/core/\n\n# Process individual file\naid src/main.py\n\n# Include protected/private for deeper analysis\naid ./my-project --private=1 --protected=1\n\n# Include implementations for small projects\naid ./my-small-lib --implementation=1\n\n# Everything for complete understanding\naid ./micro-service --private=1 --protected=1 --implementation=1\n```\n\n**Granular Control**: Process your entire codebase, specific modules, directories, or even individual files. Perfect for focusing AI on the exact context it needs - whether that's understanding the whole system architecture or diving deep into a specific authentication module.\n\nüìà **[Full benchmark details](benchmark/BENCHMARK_RESULTS.md)** | üß™ **[Reproduce these results](benchmark/test_benchmark.sh)**\n\n## üöÄ Quick Start\n\n### One-Line Installation\n\n**macOS / Linux / WSL:**\n```bash\n# Install to ~/.aid/bin (recommended, no sudo required)\ncurl -sSL https://raw.githubusercontent.com/janreges/ai-distiller/main/install.sh | bash\n\n# Install to /usr/local/bin (requires sudo)\ncurl -sSL https://raw.githubusercontent.com/janreges/ai-distiller/main/install.sh | bash -s -- --sudo\n```\n\n**Windows PowerShell:**\n```powershell\niwr https://raw.githubusercontent.com/janreges/ai-distiller/main/install.ps1 -useb | iex\n```\n\nThe installer will:\n- Detect your OS and architecture automatically\n- Download the appropriate pre-built binary\n- Install to `~/.aid/bin/aid` by default (no sudo required)\n- Or to `/usr/local/bin/aid` with `--sudo` flag\n- Guide you through PATH configuration if needed\n\n### Basic Usage\n\n```bash\n# Basic usage\naid .                                   # Current directory, output is saved to file in ./aid\naid . --stdout                          # Current directory, output is printed to STDOUT\naid src/                                # Specific directory\naid main.py                             # Specific file\n\n```\n\n## üìñ Example Output\n\n<details>\n<summary>Python Class Example</summary>\n\n**Input** (`car.py`):\n```python\nclass Car:\n    \"\"\"A car with basic attributes and methods.\"\"\"\n    \n    def __init__(self, make: str, model: str):\n        self.make = make\n        self.model = model\n        self._mileage = 0  # Private\n    \n    def drive(self, distance: int) -> None:\n        \"\"\"Drive the car.\"\"\"\n        if distance > 0:\n            self._mileage += distance\n```\n\n**Output** (`aid car.py --format text --implementation=0`):\n```\n<file path=\"car.py\">\nclass Car:\n    +def __init__(self, make: str, model: str)\n    +def drive(self, distance: int) -> None\n</file>\n```\n\n</details>\n\n<details>\n<summary>TypeScript Interface Example</summary>\n\n**Input** (`api.ts`):\n```typescript\nexport interface User {\n  id: number;\n  name: string;\n  email?: string;\n}\n\nexport class UserService {\n  private cache = new Map<number, User>();\n  \n  async getUser(id: number): Promise<User | null> {\n    return this.cache.get(id) || null;\n  }\n}\n```\n\n**Output** (`aid api.ts --format text --implementation=0`):\n```\n<file path=\"api.ts\">\nexport interface User {\n  id: number;\n  name: string;\n  email?: string;\n}\n\nexport class UserService {\n  +async getUser(id: number): Promise<User | null>\n}\n</file>\n```\n\n</details>\n\n## üìñ Guides & Examples\n\n### Deep Code Analysis Prompt Generation\n\nAI Distiller generates sophisticated analysis prompts that AI assistants can execute for comprehensive codebase understanding:\n\n```bash\naid internal \\\n   --private=1 --protected=1 --implementation=1 \\\n   --ai-action=flow-for-deep-file-to-file-analysis\n\n‚úÖ AI Analysis Task List generated successfully!\nüìã Task List: .aid/ANALYSIS-TASK-LIST.internal.2025-06-20.md\nüìä Summary File: .aid/ANALYSIS-SUMMARY.internal.2025-06-20.md\nüìÅ Analysis Reports Directory: .aid/analysis.internal/2025-06-20\nü§ñ Ready for AI-driven analysis workflow!\nüìÇ Files to analyze: 158\n\nüí° If you are an AI agent, please read the Task List above and carefully follow all instructions to systematically analyze each file.\n```\n\n**What AI Distiller generates**:\n- üìã **Task list prompt** - A structured checklist for AI to follow (`.aid/ANALYSIS-TASK-LIST.PROJECT.DATE.md`)\n- üéØ **Analysis instructions** - Detailed prompts guiding AI through security, performance, and quality checks\n- üìä **Code structure** - Distilled code included in the prompt files for AI to analyze\n- üìÅ **Directory structure** - Pre-created folders where AI agents can save their analysis results\n\n**How to use the generated prompts**:\n1. **For AI agents**: Direct the agent to read the generated task list file and follow instructions\n2. **For web AI tools**: Copy the content of generated files and paste into Gemini (best for large codebases due to 1M context)\n3. **For small codebases**: Use `--stdout` to get prompt directly without saving to file\n\n**Note**: The analysis dimensions (Security, Performance, Maintainability, Readability) are part of the prompts that guide the AI - AI Distiller itself doesn't perform any analysis.\n\n### ü§ñ Use with Claude Code/Desktop (MCP)\n\nAI Distiller now integrates seamlessly with Claude Code/Desktop through the Model Context Protocol (MCP), enabling AI agents to analyze and understand codebases directly within conversations.\n\n```bash\n# One-line installation\nclaude mcp add aid -- npx -y @janreges/ai-distiller-mcp\n```\n\nüì¶ **NPM Package**: [`@janreges/ai-distiller-mcp`](https://www.npmjs.com/package/@janreges/ai-distiller-mcp) - Full documentation and examples available\n\n#### Available MCP Tools\n\n**üîç Code Structure Tools:**\n- `distill_file` - Extract structure from a single file\n- `distill_directory` - Extract structure from entire directories\n- `list_files` - Browse directories with file statistics\n- `get_capabilities` - Get info about AI Distiller capabilities\n\n**üéØ Specialized AI Analysis Tools:**\n- `aid_hunt_bugs` - Generate bug-hunting prompts with distilled code\n- `aid_suggest_refactoring` - Create refactoring analysis prompts\n- `aid_generate_diagram` - Produce diagram generation prompts (Mermaid)\n- `aid_analyze_security` - Generate security audit prompts (OWASP Top 10)\n- `aid_generate_docs` - Create documentation generation prompts\n- `aid_deep_file_analysis` - Systematic file-by-file analysis workflow\n- `aid_multi_file_docs` - Multi-file documentation workflow\n- `aid_complex_analysis` - Enterprise-grade analysis prompts\n- `aid_performance_analysis` - Performance optimization prompts\n- `aid_best_practices` - Code quality and best practices prompts\n\n**üîß Core Analysis Engine:**\n- `aid_analyze` - Direct access to all AI actions for custom workflows\n\n**Important**: AI Distiller **generates analysis prompts** with distilled code - it does NOT perform the actual analysis! The output is a specialized prompt + distilled code that AI agents (like Claude) then execute. For large codebases, you can copy the output to tools like Gemini 2.0 with 1M context window.\n\n**Smart Context Management**: AI agents can analyze your entire project for understanding the big picture, then zoom into specific modules (auth, API, database) for detailed work. No more overwhelming AI with irrelevant code!\n\n## üìñ Complete CLI Reference\n\n### Command Synopsis\n```bash\naid <path> [OPTIONS]\n```\n\n### Core Arguments and Options\n\n#### üéØ Primary Arguments\n\n| Argument | Type | Default | Description |\n|----------|------|---------|-------------|\n| `<path>` | String | *(required)* | Path to source file or directory to analyze. Use `.git` for git history mode, `-` (or empty) for stdin input |\n\n#### üìÅ Output Options\n\n| Option | Type | Default | Description |\n|--------|------|---------|-------------|\n| `-o, --output` | String | `.aid/<dirname>.[options].txt` | Output file path. Auto-generated based on input directory basename and options if not specified |\n| `--stdout` | Flag | `false` | Print output to stdout in addition to file. When used alone, no file is created |\n| `--format` | String | `text` | Output format: `text` (ultra-compact), `md` (clean Markdown), `jsonl` (one JSON per file), `json-structured` (rich semantic data), `xml` (structured XML) |\n\n#### ü§ñ AI Actions\n\n| Option | Type | Default | Description |\n|--------|------|---------|-------------|\n| `--ai-action` | String | *(none)* | Generate pre-configured prompts with distilled code for AI analysis. See [AI Actions](#ai-actions-detailed) section below |\n| `--ai-output` | String | `./.aid/<action>.<timestamp>.<dirname>.md` | Custom output path for generated AI prompt files |\n\n#### üëÅÔ∏è Visibility Filtering\n\n| Option | Type | Default | Description |\n|--------|------|---------|-------------|\n| `--public` | 0\\|1 | `1` | Include public members (methods, functions, classes) |\n| `--protected` | 0\\|1 | `0` | Include protected members |\n| `--internal` | 0\\|1 | `0` | Include internal/package-private members |\n| `--private` | 0\\|1 | `0` | Include private members |\n\n#### üìù Content Filtering\n\n| Option | Type | Default | Description |\n|--------|------|---------|-------------|\n| `--comments` | 0\\|1 | `0` | Include inline and block comments |\n| `--docstrings` | 0\\|1 | `1` | Include documentation comments (docstrings, JSDoc, etc.) |\n| `--implementation` | 0\\|1 | `0` | Include function/method bodies (implementation details) |\n| `--imports` | 0\\|1 | `1` | Include import/require statements |\n| `--annotations` | 0\\|1 | `1` | Include decorators and annotations |\n| `--fields` | 0\\|1 | `1` | Include class fields and properties |\n| `--methods` | 0\\|1 | `1` | Include methods and functions |\n\n#### üéõÔ∏è Alternative Filtering Syntax\n\n| Option | Type | Default | Description |\n|--------|------|---------|-------------|\n| `--include-only` | String | *(none)* | Include ONLY these categories (comma-separated: `public,protected,imports`) |\n| `--exclude-items` | String | *(none)* | Exclude these categories (comma-separated: `private,comments,implementation`) |\n\n#### üìÇ File Selection\n\n| Option | Type | Default | Description |\n|--------|------|---------|-------------|\n| `--include` | String | *(all files)* | Include file patterns (comma-separated: `*.go,*.py` or multiple: `--include \"*.go\" --include \"*.py\"`) |\n| `--exclude` | String | *(none)* | Exclude file patterns (comma-separated: `*test*,*.json` or multiple: `--exclude \"*test*\" --exclude \"vendor/**\"`) |\n| `-r, --recursive` | 0\\|1 | `1` | Process directories recursively. Set to 0 to process only immediate directory contents |\n\n#### üîß Processing Options\n\n| Option | Type | Default | Description |\n|--------|------|---------|-------------|\n| `--raw` | Flag | `false` | Process all text files without language parsing. Overrides all content filters |\n| `--lang` | String | `auto` | Force language detection: `auto`, `python`, `typescript`, `javascript`, `go`, `rust`, `java`, `csharp`, `kotlin`, `cpp`, `php`, `ruby`, `swift` |\n\n#### üìç Path Control\n\n| Option | Type | Default | Description |\n|--------|------|---------|-------------|\n| `--file-path-type` | String | `relative` | Path format in output: `relative` or `absolute` |\n| `--relative-path-prefix` | String | *(empty)* | Custom prefix for relative paths (e.g., `module/` ‚Üí `module/src/file.go`) |\n\n#### ‚ö° Performance Options\n\n| Option | Type | Default | Description |\n|--------|------|---------|-------------|\n| `-w, --workers` | Integer | `0` | Number of parallel workers. `0` = auto (80% of CPU cores), `1` = serial processing, `2+` = specific worker count |\n\n#### üìä Summary Output Options\n\n| Option | Type | Default | Description |\n|--------|------|---------|-------------|\n| `--summary-type` | String | `visual-progress-bar` | Summary format after processing. See [Summary Types](#summary-types) below |\n| `--no-emoji` | Flag | `false` | Disable emojis in summary output for plain text terminals |\n\n#### üìú Git Mode Options (when path is `.git`)\n\n| Option | Type | Default | Description |\n|--------|------|---------|-------------|\n| `--git-limit` | Integer | `200` | Number of commits to analyze. Use `0` for all commits |\n| `--with-analysis-prompt` | Flag | `false` | Add comprehensive AI analysis prompt for commit quality, patterns, and insights |\n\n#### üêõ Diagnostic Options\n\n| Option | Type | Default | Description |\n|--------|------|---------|-------------|\n| `-v, --verbose` | Count | `0` | Verbose output. Use `-vv` for detailed info, `-vvv` for full trace with data dumps |\n| `--version` | Flag | `false` | Show version information and exit |\n| `--help` | Flag | `false` | Show help message |\n| `--help-extended` | Flag | `false` | Show complete documentation (man page style) |\n| `--cheat` | Flag | `false` | Show quick reference card |\n\n### AI Actions Detailed\n\nAI actions generate pre-configured prompts combined with distilled code that AI agents can then execute for specific analysis tasks:\n\n| Action | Generated Prompt Type | AI Agent Will |\n|--------|-------------|----------|\n| `prompt-for-refactoring-suggestion` | Refactoring analysis prompt with distilled code | Analyze code for improvements, technical debt, effort sizing |\n| `prompt-for-complex-codebase-analysis` | Enterprise-grade analysis prompt with full codebase | Generate architecture diagrams, compliance checks, findings |\n| `prompt-for-security-analysis` | Security audit prompt with OWASP Top 10 guidelines | Detect vulnerabilities, suggest remediation steps |\n| `prompt-for-performance-analysis` | Performance optimization prompt with complexity focus | Identify bottlenecks, analyze scalability issues |\n| `prompt-for-best-practices-analysis` | Code quality prompt with industry standards | Assess code quality, suggest improvements |\n| `prompt-for-bug-hunting` | Bug detection prompt with pattern analysis | Find bugs, analyze quality metrics |\n| `prompt-for-single-file-docs` | Documentation generation prompt for single file | Create comprehensive API documentation |\n| `prompt-for-diagrams` | Diagram generation prompt with Mermaid syntax | Generate 10+ architecture and process diagrams |\n| `flow-for-deep-file-to-file-analysis` | Systematic analysis task list with directory structure | Perform file-by-file deep analysis |\n| `flow-for-multi-file-docs` | Documentation workflow with file relationships | Create interconnected documentation |\n\n### Summary Types\n\n| Type | Description | Example Output |\n|------|-------------|----------------|\n| `visual-progress-bar` | Default. Shows compression progress bar with colors | `‚úÖ Distilled 150 files [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë] 85% (5MB ‚Üí 750KB)` |\n| `stock-ticker` | Compact stock market style | `üìä AID 97.5% ‚ñ≤ \\| 5MB‚Üí128KB \\| ~1.2M tokens saved` |\n| `speedometer-dashboard` | Multi-line dashboard with detailed metrics | Shows files, size, tokens, processing time in box format |\n| `minimalist-sparkline` | Single line with sparkline visualization | `‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà 150 files ‚Üí 97.5% reduction (750KB) ‚úì` |\n| `ci-friendly` | Clean format for CI/CD pipelines | `[aid] ‚úì 85.9% saved \\| 21 kB ‚Üí 2.9 kB \\| 4ms` |\n| `json` | Machine-readable JSON output | `{\"original_bytes\":5242880,\"distilled_bytes\":131072,...}` |\n| `off` | Disable summary output | No summary displayed |\n\n### Exit Codes\n\n| Code | Meaning |\n|------|---------|\n| `0` | Success |\n| `1` | General error (file not found, parse error, etc.) |\n| `2` | Invalid arguments or conflicting options |\n\n### Examples\n\n```bash\n# Basic usage - distill with default settings (public APIs only)\naid ./src\n\n# Include all visibility levels and implementation\naid ./src --private=1 --protected=1 --internal=1 --implementation=1\n\n# Generate security analysis prompt (AI agent will execute the analysis)\naid --ai-action prompt-for-security-analysis ./api --private=1\n\n# Process only Python and Go files, exclude tests\naid --include \"*.py,*.go\" --exclude \"*test*,*spec*\" ./\n\n# Git history analysis with AI insights\naid .git --with-analysis-prompt --git-limit=500\n\n# Raw text processing for documentation\naid ./docs --raw\n\n# Force single-threaded processing for debugging (-v, -vv, -vvv)\naid ./complex-code -w 1 -vv\n\n# Custom output with absolute paths\naid ./lib --output=/tmp/analysis.txt --file-path-type=absolute\n\n# CI/CD integration with clean output\naid ./internal --summary-type=ci-friendly --no-emoji\n```\n\n## ‚ö†Ô∏è Limitations\n\n- **Syntax Errors**: Files with syntax errors may be skipped or partially processed\n- **Dynamic Features**: Runtime-determined types/interfaces in dynamic languages are not resolved\n- **Macro Expansion**: Complex macros (Rust, C++) show pre-expansion source\n- **Generated Code**: Consider using `.aidignore` to skip generated files\n\n## üîí Security Considerations\n\n**‚ö†Ô∏è Important**: AI Distiller extracts code structure which may include:\n- Function and variable names that could reveal business logic (e.g., `processPayment`, `calculateTaxEvasion`)\n- API endpoints and internal routes (e.g., `/api/v1/internal/user-data`)\n- Type information and data structures\n- Comments and docstrings (unless stripped)\n- File paths revealing project structure or codenames\n\n**Recommendations**:\n1. Always review output before sending to external services\n2. Use `--comments=0` to remove potentially sensitive documentation\n3. Consider running a secrets scanner on your codebase first\n4. For maximum security, run AI Distiller in an isolated environment\n5. Future: We're exploring an `--obfuscate` flag to anonymize sensitive identifiers\n\n\n## üõ†Ô∏è Advanced Usage\n\n### ‚ö° Parallel Processing\n\nAI Distiller now supports parallel processing for significantly faster analysis of large codebases:\n\n```bash\n# Use default parallel processing (80% of CPU cores)\naid ./src\n\n# Force serial processing (original behavior)\naid ./src -w 1\n\n# Use specific number of workers\naid ./src -w 16\n\n# Check performance with verbose output\naid ./src -v  # Shows: \"Using 25 parallel workers (32 CPU cores available)\"\n```\n\n**Performance Benefits**:\n- React packages: 3.5s ‚Üí 0.5s (7x faster)\n- Large codebases: Near-linear speedup with CPU cores\n- Maintains identical output order as serial processing\n\n### Processing from stdin\n\nAI Distiller can process code directly from stdin, perfect for:\n- Quick code snippet analysis\n- Pipeline integration\n- Testing without creating files\n- Dynamic code generation workflows\n\n```bash\n# Auto-detect language from stdin\necho 'class User { getName() { return this.name; } }' | aid --format text\n\n# Explicit language specification\ncat mycode.php | aid --lang php --private=0 --protected=0\n\n# Use \"-\" to explicitly read from stdin\naid - --lang python < snippet.py\n\n# Pipeline example: extract structure from generated code\ngenerate-code.sh | aid --lang typescript --format json\n```\n\n**Language Detection**: When using stdin without `--lang`, AI Distiller automatically detects the language based on syntax patterns. Supported languages for auto-detection: python, typescript, javascript, go, ruby, swift, rust, java, c#, kotlin, c++, php.\n\n### Integration with AI Tools\n\n```bash\n# Create a context file for Claude or GPT\naid ./src --format text --implementation=0 > context.txt\n\n# Generate a codebase summary for RAG systems\naid . --format json-structured | jq -r '.files[].symbols[].name' > symbols.txt\n\n# Extract API surface for documentation\naid ./api --comments=0 --implementation=0 --format md > api-ref.md\n\n# Extract only method signatures (no fields/properties) - great for large codebases\naid ./src --fields=0 --implementation=0 > methods-only.txt\n\n# Extract only data structures (no method noise)  \naid ./models --methods=0 > data-structures.txt\n\n# Focus on public API methods only\naid ./services --fields=0 --private=0 --protected=0 --internal=0\n```\n\n### üö´ Ignoring Files with .aidignore\n\nAI Distiller respects `.aidignore` files for excluding files and directories from processing. The syntax is similar to `.gitignore`.\n\n#### Important: What AI Distiller Processes\n\nAI Distiller only processes source code files with these extensions:\n- **Python**: `.py`, `.pyw`, `.pyi`\n- **JavaScript**: `.js`, `.mjs`, `.cjs`, `.jsx`\n- **TypeScript**: `.ts`, `.tsx`, `.d.ts`\n- **Go**: `.go`\n- **Rust**: `.rs`\n- **Ruby**: `.rb`, `.rake`, `.gemspec`\n- **Java**: `.java`\n- **C#**: `.cs`\n- **Kotlin**: `.kt`, `.kts`\n- **C++**: `.cpp`, `.cc`, `.cxx`, `.c++`, `.h`, `.hpp`, `.hh`, `.hxx`, `.h++`\n- **PHP**: `.php`, `.phtml`, `.php3`, `.php4`, `.php5`, `.php7`, `.phps`, `.inc`\n- **Swift**: `.swift`\n\n**Note**: Files like `.log`, `.txt`, `.md`, images, PDFs, and other non-source files are automatically ignored by AI Distiller, so you don't need to add them to `.aidignore`.\n\n#### Default Ignored Directories\n\nAI Distiller automatically ignores these common dependency and build directories:\n- `node_modules/` - npm packages\n- `vendor/` - Go and PHP dependencies\n- `target/` - Rust build output\n- `build/`, `dist/` - Common build directories\n- `__pycache__/`, `.pytest_cache/`, `venv/`, `.venv/`, `env/`, `.env/` - Python\n- `.gradle/`, `gradle/` - Java/Kotlin\n- `Pods/` - Swift/iOS dependencies\n- `.bundle/` - Ruby bundler\n- `bin/`, `obj/` - Compiled binaries\n- `.vs/`, `.idea/`, `.vscode/` - IDE directories\n- `coverage/`, `.nyc_output/` - Test coverage\n- `bower_components/` - Legacy JavaScript\n- `.terraform/` - Terraform\n- `.git/`, `.svn/`, `.hg/` - Version control\n\nYou can override these defaults using `!` patterns in `.aidignore` (see Advanced Usage below).\n\n#### Basic Syntax\n\nCreate a `.aidignore` file in your project root or any subdirectory:\n\n```bash\n# Comments start with hash\n*.test.js          # Ignore test files\n*.spec.ts          # Ignore spec files\ntemp/              # Ignore temp directory\nbuild/             # Ignore build directory\n/secrets.py        # Ignore secrets.py only in root\nnode_modules/      # Ignore node_modules everywhere\n**/*.bak           # Ignore .bak files in any directory\nsrc/test_*         # Ignore test_* files in src/\n!important.test.js # Don't ignore important.test.js (negation)\n```\n\n#### How It Works\n\n- `.aidignore` files work recursively - place them in any directory\n- Patterns are relative to the directory containing the `.aidignore` file\n- Use `/` prefix for patterns relative to the `.aidignore` location\n- Use `**` for recursive matching\n- Directory patterns should end with `/`\n- Use `!` prefix to negate a pattern (re-include previously ignored files)\n\n#### Examples\n\n```bash\n# .aidignore in project root\nnode_modules/       # Excludes all node_modules directories\n*.test.js          # Excludes all test files\n*.spec.ts          # Excludes all spec files\ndist/              # Excludes dist directory\n.env.py            # Excludes environment config files\nvendor/            # Excludes vendor directory\n\n# More specific patterns\nsrc/**/test_*.py   # Test files in src subdirectories\n!src/test_utils.py # But include this specific test file\n/config/*.local.py # Local config files in root config dir\n**/*_generated.go  # Generated Go files anywhere\n```\n\n#### Advanced Usage: Including Normally Ignored Content\n\n##### Include Default-Ignored Directories\n\nUse `!` patterns to include directories that are ignored by default:\n\n```bash\n# Include vendor directory for analysis\n!vendor/\n\n# Include specific node_modules package\n!node_modules/my-local-package/\n\n# Include Python virtual environment\n!venv/\n```\n\n##### Include Non-Source Files\n\nYou can also include files that AI Distiller normally doesn't process:\n\n```bash\n# Include all markdown files\n!*.md\n!**/*.md\n\n# Include configuration files\n!*.yaml\n!*.json\n!.env\n\n# Include specific documentation\n!docs/**/*.txt\n!README.md\n!CHANGELOG.md\n```\n\nWhen you include non-source files with `!` patterns, AI Distiller will include their raw content in the output.\n\n#### Nested .aidignore Files\n\nYou can place `.aidignore` files in subdirectories for more specific control:\n\n```bash\n# project/.aidignore\n*.test.py\n!vendor/            # Include vendor in this project\n\n# project/src/.aidignore\ntest_*.go\n*.mock.ts\n!test_helpers.ts   # Exception: include test_helpers.ts\n```\n\n### üéØ Git History Analysis Mode\n\nAI Distiller includes a special mode for analyzing git repositories. When you pass a `.git` directory, it switches to git log mode:\n\n```bash\n# View formatted git history\naid .git\n\n# Limit to recent commits (default is 200)\naid .git --git-limit=500\n\n# Include AI analysis prompt for comprehensive insights\naid .git --git-limit=1000 --with-analysis-prompt\n```\n\nThe `--with-analysis-prompt` flag adds a sophisticated prompt combined with git history that AI agents can use to generate:\n- **Contributor statistics** with expertise areas and collaboration patterns\n- **Timeline analysis** with development phases and activity visualization\n- **Functional categorization** of commits (features, fixes, refactoring)\n- **Codebase evolution insights** including technology shifts\n- **Actionable recommendations** based on discovered patterns\n\nThe output file contains both the analysis prompt and formatted git history, ready for AI agents to process. Perfect for understanding project history, identifying knowledge silos, or generating impressive development reports.\n\n## ‚ùì FAQ\n\n<details>\n<summary><strong>How accurate are the token counts?</strong></summary>\n\nToken counts are estimated using OpenAI's cl100k_base tokenizer (1 token ‚âà 4 characters). Actual token usage varies by model - Claude and GPT-4 use similar tokenizers, while others may differ by ¬±10%.\n</details>\n\n<details>\n<summary><strong>Can AI Distiller handle very large repositories?</strong></summary>\n\nYes! We've tested on repositories with 50,000+ files. The parallel processing mode (`-w` flag) scales linearly with CPU cores. Memory usage is bounded - large files are processed in streaming chunks.\n</details>\n\n<details>\n<summary><strong>What about generated code and vendor directories?</strong></summary>\n\nCreate a `.aidignore` file (same syntax as `.gitignore`) to exclude generated files, vendor directories, or any paths you don't want processed.\n</details>\n\n<details>\n<summary><strong>What happens with unsupported file types?</strong></summary>\n\nFiles with unknown or unsupported extensions are automatically skipped - no errors, no interruption. AI Distiller only processes files it has parsers for, ensuring clean and relevant output. This means you can safely run it on mixed repositories containing documentation, images, configs, etc.\n</details>\n\n<details>\n<summary><strong>Is my code sent anywhere?</strong></summary>\n\nNo! AI Distiller runs 100% locally. It only extracts and formats your code structure - you decide what to do with the output. The tool itself makes no network connections.\n</details>\n\n<details>\n<summary><strong>Which programming languages are supported?</strong></summary>\n\nCurrently 12+ languages via tree-sitter: Python, TypeScript, JavaScript, Go, Java, C#, Rust, Ruby, Swift, Kotlin, PHP, C++. All parsers are bundled in the binary - no external dependencies needed.\n</details>\n\n## ü§ù Contributing\n\nWe welcome contributions! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.\n\n### Development Setup\n\n```bash\n# Clone and setup\ngit clone https://github.com/janreges/ai-distiller\ncd ai-distiller\nmake dev-init    # Initialize development environment\n\n# Run tests\nmake test         # Unit tests\nmake test-integration  # Integration tests\n\n# Build binary\nmake build        # Build for current platform\n```\n\n### Building Release Binaries\n\nAI Distiller requires CGO for full language support via tree-sitter parsers. To build release binaries for all supported platforms:\n\n#### Prerequisites\n\n**Ubuntu/Debian:**\n```bash\n# Install cross-compilation toolchains\nsudo apt-get update\nsudo apt-get install -y gcc-aarch64-linux-gnu gcc-mingw-w64-x86-64\n\n# For macOS cross-compilation, you need osxcross:\n# 1. Clone osxcross: git clone https://github.com/tpoechtrager/osxcross tools/osxcross\n# 2. Obtain macOS SDK (see https://github.com/tpoechtrager/osxcross#packaging-the-sdk)\n# 3. Place SDK in tools/osxcross/tarballs/\n# 4. Build osxcross: cd tools/osxcross && ./build.sh\n```\n\n#### Build All Platforms\n\n```bash\n# Build release archives for all platforms\n./scripts/build-releases.sh\n\n# This creates:\n# - aid-linux-amd64.tar.gz    (Linux 64-bit)\n# - aid-linux-arm64.tar.gz    (Linux ARM64)\n# - aid-darwin-amd64.tar.gz   (macOS Intel)\n# - aid-darwin-arm64.tar.gz   (macOS Apple Silicon)\n# - aid-windows-amd64.zip     (Windows 64-bit)\n```\n\nThe script automatically detects available toolchains and builds for all possible platforms. Each archive contains the `aid` binary (or `aid.exe` for Windows) with full language support.\n\n**Note**: Without proper toolchains, only the native platform will be built.\n\n## üìÑ License\n\nMIT License - see [LICENSE](LICENSE) for details.\n\n## üôè Acknowledgments\n\n- Built on [tree-sitter](https://tree-sitter.github.io/) for accurate parsing\n- Inspired by the need for better AI-code interaction\n- Created with ‚ù§Ô∏è by Claude Code & J√°n Rege≈° from [SiteOne](https://www.siteone.io/) (Czech Republic).\n",
  "category": "AI Tools",
  "quality_score": 47,
  "archestra_config": {
    "client_config_permutations": {
      "mcpServers": {
        "janreges-ai-distiller-mcp": {
          "command": "aid",
          "args": ["--mcp-server", "--port", "8080"],
          "env": {}
        }
      }
    },
    "oauth": {
      "provider": null,
      "required": false
    }
  },
  "github_info": {
    "owner": "janreges",
    "repo": "ai-distiller",
    "url": "https://github.com/janreges/ai-distiller",
    "name": "ai-distiller",
    "path": null,
    "stars": 72,
    "contributors": 1,
    "issues": 6,
    "releases": true,
    "ci_cd": true,
    "latest_commit_hash": "7790d3b203c6825ed4a7471deef950662eb2f694"
  },
  "programming_language": "C",
  "framework": null,
  "last_scraped_at": "2025-08-04T09:36:05.974Z",
  "evaluation_model": "gemini-2.5-flash",
  "protocol_features": {
    "implementing_tools": false,
    "implementing_prompts": true,
    "implementing_resources": true,
    "implementing_sampling": false,
    "implementing_roots": false,
    "implementing_logging": false,
    "implementing_stdio": true,
    "implementing_streamable_http": false,
    "implementing_oauth2": false
  },
  "dependencies": [
    {
      "name": "@modelcontextprotocol/sdk",
      "importance": 10
    },
    {
      "name": "smacker/go-tree-sitter",
      "importance": 9
    },
    {
      "name": "spf13/cobra",
      "importance": 8
    },
    {
      "name": "tetratelabs/wazero",
      "importance": 8
    },
    {
      "name": "tree-sitter-swift",
      "importance": 7
    },
    {
      "name": "tree-sitter-typescript",
      "importance": 7
    },
    {
      "name": "tree-sitter/tree-sitter-c-sharp",
      "importance": 7
    },
    {
      "name": "tree-sitter/tree-sitter-cpp",
      "importance": 7
    },
    {
      "name": "tree-sitter/tree-sitter-java",
      "importance": 7
    },
    {
      "name": "tree-sitter/tree-sitter-javascript",
      "importance": 7
    },
    {
      "name": "tree-sitter/tree-sitter-php",
      "importance": 7
    },
    {
      "name": "tree-sitter/tree-sitter-ruby",
      "importance": 7
    },
    {
      "name": "zod",
      "importance": 6
    },
    {
      "name": "tar",
      "importance": 5
    },
    {
      "name": "stretchr/testify",
      "importance": 4
    },
    {
      "name": "davecgh/go-spew",
      "importance": 3
    },
    {
      "name": "dustin/go-humanize",
      "importance": 3
    },
    {
      "name": "golang.org/x/term",
      "importance": 3
    },
    {
      "name": "mattn/go-isatty",
      "importance": 3
    },
    {
      "name": "golang.org/x/sys",
      "importance": 2
    },
    {
      "name": "gopkg.in/yaml.v3",
      "importance": 2
    },
    {
      "name": "inconshreveable/mousetrap",
      "importance": 2
    },
    {
      "name": "pmezard/go-difflib",
      "importance": 2
    },
    {
      "name": "spf13/pflag",
      "importance": 2
    }
  ],
  "raw_dependencies": "=== go.mod ===\nmodule github.com/janreges/ai-distiller\n\ngo 1.23.0\n\ntoolchain go1.23.8\n\nrequire (\n\tgithub.com/davecgh/go-spew v1.1.1\n\tgithub.com/dustin/go-humanize v1.0.1\n\tgithub.com/mattn/go-isatty v0.0.20\n\tgithub.com/smacker/go-tree-sitter v0.0.0-20240827094217-dd81d9e9be82\n\tgithub.com/spf13/cobra v1.9.1\n\tgithub.com/stretchr/testify v1.10.0\n\tgithub.com/tetratelabs/wazero v1.9.0\n\tgithub.com/tree-sitter/tree-sitter-c-sharp v0.23.1\n\tgithub.com/tree-sitter/tree-sitter-cpp v0.23.4\n\tgithub.com/tree-sitter/tree-sitter-java v0.23.5\n\tgithub.com/tree-sitter/tree-sitter-javascript v0.23.1\n\tgithub.com/tree-sitter/tree-sitter-php v0.23.12\n\tgithub.com/tree-sitter/tree-sitter-ruby v0.23.1\n\tgolang.org/x/term v0.32.0\n\ttree-sitter-swift v0.0.0\n\ttree-sitter-typescript v0.0.0\n)\n\nreplace tree-sitter-swift => ./internal/parser/grammars/tree-sitter-swift\n\nreplace tree-sitter-typescript => ./internal/parser/grammars/tree-sitter-typescript\n\n// replace tree-sitter-rust => ./internal/parser/grammars/tree-sitter-rust\n\nrequire (\n\tgithub.com/inconshreveable/mousetrap v1.1.0 // indirect\n\tgithub.com/pmezard/go-difflib v1.0.0 // indirect\n\tgithub.com/spf13/pflag v1.0.6 // indirect\n\tgolang.org/x/sys v0.33.0 // indirect\n\tgopkg.in/yaml.v3 v3.0.1 // indirect\n)\n\n\n=== mcp-npm/package.json ===\n{\n  \"name\": \"@janreges/ai-distiller-mcp\",\n  \"version\": \"1.3.3\",\n  \"description\": \"AI Distiller (aid) - Essential code structure extractor for LLMs. Provides AI with accurate code signatures, data types, and API contracts from your actual codebase, reducing guesswork and trial-error coding. Accelerates analysis workflows including security audits, performance reviews, git history insights, refactoring suggestions, and comprehensive structural analysis.\",\n  \"keywords\": [\n    \"mcp\",\n    \"model-context-protocol\",\n    \"aid\",\n    \"ai-distiller\",\n    \"code-analysis\",\n    \"claude\",\n    \"llm\",\n    \"codebase-analysis\"\n  ],\n  \"author\": \"Jan Reges\",\n  \"license\": \"MIT\",\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"git+https://github.com/janreges/ai-distiller.git\"\n  },\n  \"bugs\": {\n    \"url\": \"https://github.com/janreges/ai-distiller/issues\"\n  },\n  \"homepage\": \"https://github.com/janreges/ai-distiller#readme\",\n  \"main\": \"mcp-server-wrapper.js\",\n  \"types\": \"dist/mcp-server-sdk.d.ts\",\n  \"bin\": {\n    \"aid-mcp\": \"mcp-server-wrapper.js\"\n  },\n  \"scripts\": {\n    \"build\": \"tsc\",\n    \"watch\": \"tsc --watch\",\n    \"postinstall\": \"node scripts/postinstall.js\",\n    \"prepublishOnly\": \"npm run build\",\n    \"test\": \"echo \\\"No tests yet\\\"\"\n  },\n  \"files\": [\n    \"dist/\",\n    \"bin/.gitkeep\",\n    \"scripts/postinstall.js\",\n    \"mcp-server-wrapper.js\",\n    \"README.md\",\n    \"LICENSE\"\n  ],\n  \"engines\": {\n    \"node\": \">=18.0.0\"\n  },\n  \"publishConfig\": {\n    \"access\": \"public\"\n  },\n  \"dependencies\": {\n    \"@modelcontextprotocol/sdk\": \"^1.13.0\",\n    \"tar\": \"^6.2.0\",\n    \"zod\": \"^3.22.4\"\n  },\n  \"devDependencies\": {\n    \"@types/node\": \"^20.11.0\",\n    \"typescript\": \"^5.3.3\"\n  }\n}\n"
}
