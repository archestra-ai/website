{
  "dxt_version": "0.1.0",
  "name": "iunera__druid-mcp-server",
  "display_name": "druid-mcp-server",
  "version": "1.0.0",
  "description": "A comprehensive Model Context Protocol (MCP) server for Apache Druid that provides extensive tools, resources, and AI-assisted prompts for managing and analyzing Druid clusters. Built with Spring Boot and Spring AI, this server enables seamless integration between AI assistants and Apache Druid through standardized MCP protocol.",
  "author": {
    "name": "iunera"
  },
  "server": {
    "type": "binary",
    "entry_point": "index.js",
    "mcp_config": {
      "command": "unknown",
      "args": [],
      "env": {}
    }
  },
  "tools": [],
  "prompts": [],
  "keywords": [],
  "user_config": {},
  "readme": "# Druid MCP Server\n[![Trust Score](https://archestra.ai/mcp-catalog/api/badge/quality/iunera/druid-mcp-server)](https://archestra.ai/mcp-catalog/iunera__druid-mcp-server)\n\nA comprehensive Model Context Protocol (MCP) server for Apache Druid that provides extensive tools, resources, and prompts for managing and analyzing Druid clusters.\n\n*Developed by [iunera](https://www.iunera.com) - Advanced AI and Data Analytics Solutions*\n\n## Overview\n\nThis MCP server implements a feature-based architecture where each package represents a distinct functional area of Druid management. The server provides three main types of MCP components:\n\n- **Tools** - Executable functions for performing operations\n- **Resources** - Data providers for accessing information  \n- **Prompts** - AI-assisted guidance templates\n\n## Video Walkthrough\n\nLearn how to integrate AI agents with Apache Druid using the MCP server. This tutorial demonstrates time series data exploration, statistical analysis, and data ingestion using natural language with AI assistants like Claude, ChatGPT, and Gemini.\n\n[![Time Series on AI Steroids: Apache Druid Enterprise MCP Server Tutorial](https://img.youtube.com/vi/BqCEWRZbRjU/0.jpg)](https://www.youtube.com/watch?v=BqCEWRZbRjU)\n\n*Click the thumbnail above to watch the video on YouTube*\n\n## Features\n\n- Spring AI MCP Server integration\n- Tool-based architecture for MCP protocol compliance\n- STDIO and SSE transport support\n- Comprehensive error handling\n- Customizable prompt templates\n- Feature-based package organization\n\n\n### MCP Inspector Interface\n\nWhen connected to an MCP client, you can inspect the available tools, resources, and prompts through the MCP inspector interface:\n\n#### Available Tools\n![MCP Inspector - Tools](assets/images/mcpinspector-tools.png)\n\nThe tools interface shows all available Druid management functions organized by feature areas including data management, ingestion management, and monitoring & health.\n\n#### Available Resources\n![MCP Inspector - Resources](assets/images/mcpinspector-resources.png)\n\nThe resources interface displays all accessible Druid data sources and metadata that can be retrieved through the MCP protocol.\n\n#### Available Prompts\n![MCP Inspector - Prompts](assets/images/mcpinspector-prompts.png)\n\nThe prompts interface shows all AI-assisted guidance templates available for various Druid management tasks and data analysis workflows.\n\n\n\n\n## Quick Start\n\n### Prerequisites\n- Java 24\n- Maven 3.6+\n- Apache Druid cluster running with router on port 8888\n\n### Build and Run\n```bash\n# Build the application\nmvn clean package -DskipTests\n\n# Run the application\njava -jar target/druid-mcp-server-1.0.0.jar\n```\n\nThe server will start on port 8080 by default.\n\nFor detailed build instructions, testing, Docker setup, and development guidelines, see [development.md](development.md).\n\n## Installation from Maven Central\n\nIf you prefer to use the pre-built JAR without building from source, you can download and run it directly from Maven Central.\n\n### Prerequisites\n- Java 24 JRE only\n\n### Download and Run\n\n```bash\n# Create a directory for the application\nmkdir druid-mcp-server && cd druid-mcp-server\n\n# Download the JAR from Maven Central\ncurl -L -o druid-mcp-server-1.0.0.jar \\\n  \"https://repo.maven.apache.org/maven2/com/iunera/druid-mcp-server/1.0.0/druid-mcp-server-1.0.0.jar\"\n\n# Run with SSE Transport (HTTP-based, default)\njava -jar druid-mcp-server-1.0.0.jar\n\n# OR run with STDIO Transport (recommended for LLM clients)\njava -Dspring.ai.mcp.server.stdio=true \\\n     -Dspring.main.web-application-type=none \\\n     -Dlogging.pattern.console= \\\n     -jar druid-mcp-server-1.0.0.jar\n```\n\n## Installation with Docker\n\nIf you prefer to use Docker, you can run the pre-built Docker image directly from Docker Hub without any local Java installation.\n\n### Prerequisites\n- Docker installed and running\n\n### Pull and Run\n\n```bash\n# Pull the latest Docker image\ndocker pull iunera/druid-mcp-server:latest\n\n# Run with SSE Transport (HTTP-based, default)\ndocker run -p 8080:8080 \\\n  -e DRUID_BROKER_URL=http://your-druid-broker:8082 \\\n  -e DRUID_COORDINATOR_URL=http://your-druid-coordinator:8081 \\\n  iunera/druid-mcp-server:latest\n\n# OR run with STDIO Transport (recommended for LLM clients)\ndocker run --rm -i \\\n  -e SPRING_AI_MCP_SERVER_STDIO=true \\\n  -e SPRING_MAIN_WEB_APPLICATION_TYPE=none \\\n  -e LOGGING_PATTERN_CONSOLE= \\\n  -e DRUID_BROKER_URL=http://your-druid-broker:8082 \\\n  -e DRUID_COORDINATOR_URL=http://your-druid-coordinator:8081 \\\n  iunera/druid-mcp-server:latest\n```\n\nReplace `your-druid-broker` and `your-druid-coordinator` with your actual Druid cluster endpoints.\n\n## For Developers\n\nFor detailed development information including build instructions, testing guidelines, architecture details, and contributing guidelines, see [development.md](development.md).\n\n## Available Tools by Feature\n\n### Data Management\n\n| Feature | Tool | Description | Parameters |\n|---------|------|-------------|------------|\n| **Datasource** | `listDatasources` | List all available Druid datasource names | None |\n| **Datasource** | `showDatasourceDetails` | Show detailed information for a specific datasource including column information | `datasourceName` (String) |\n| **Datasource** | `killDatasource` | Kill a datasource permanently, removing all data and metadata | `datasourceName` (String), `interval` (String) |\n| **Lookup** | `listLookups` | List all available Druid lookups from the coordinator | None |\n| **Lookup** | `getLookupConfig` | Get configuration for a specific lookup | `tier` (String), `lookupName` (String) |\n| **Lookup** | `updateLookupConfig` | Update configuration for a specific lookup | `tier` (String), `lookupName` (String), `config` (String) |\n| **Segments** | `listAllSegments` | List all segments across all datasources | None |\n| **Segments** | `getSegmentMetadata` | Get metadata for specific segments | `datasourceName` (String), `segmentId` (String) |\n| **Segments** | `getSegmentsForDatasource` | Get all segments for a specific datasource | `datasourceName` (String) |\n| **Query** | `queryDruidSql` | Execute a SQL query against Druid datasources | `sqlQuery` (String) |\n| **Retention** | `viewRetentionRules` | View retention rules for all datasources or a specific one | `datasourceName` (String, optional) |\n| **Retention** | `updateRetentionRules` | Update retention rules for a datasource | `datasourceName` (String), `rules` (String) |\n| **Compaction** | `viewAllCompactionConfigs` | View compaction configurations for all datasources | None |\n| **Compaction** | `viewCompactionConfigForDatasource` | View compaction configuration for a specific datasource | `datasourceName` (String) |\n| **Compaction** | `editCompactionConfigForDatasource` | Edit compaction configuration for a datasource | `datasourceName` (String), `config` (String) |\n| **Compaction** | `deleteCompactionConfigForDatasource` | Delete compaction configuration for a datasource | `datasourceName` (String) |\n| **Compaction** | `viewCompactionStatus` | View compaction status for all datasources | None |\n| **Compaction** | `viewCompactionStatusForDatasource` | View compaction status for a specific datasource | `datasourceName` (String) |\n\n### Ingestion Management\n\n| Feature | Tool | Description | Parameters |\n|---------|------|-------------|------------|\n| **Ingestion Spec** | `createBatchIngestionTemplate` | Create a batch ingestion template | `datasourceName` (String), `inputSource` (String), `timestampColumn` (String) |\n| **Ingestion Spec** | `createIngestionSpec` | Create and submit an ingestion specification | `specJson` (String) |\n| **Supervisors** | `listSupervisors` | List all streaming ingestion supervisors | None |\n| **Supervisors** | `getSupervisorStatus` | Get status of a specific supervisor | `supervisorId` (String) |\n| **Supervisors** | `suspendSupervisor` | Suspend a streaming supervisor | `supervisorId` (String) |\n| **Supervisors** | `startSupervisor` | Start or resume a streaming supervisor | `supervisorId` (String) |\n| **Supervisors** | `terminateSupervisor` | Terminate a streaming supervisor | `supervisorId` (String) |\n| **Tasks** | `listTasks` | List all ingestion tasks | None |\n| **Tasks** | `getTaskStatus` | Get status of a specific task | `taskId` (String) |\n| **Tasks** | `shutdownTask` | Shutdown a running task | `taskId` (String) |\n\n### Monitoring & Health\n\n| Feature | Tool | Description | Parameters |\n|---------|------|-------------|------------|\n| **Basic Health** | `checkClusterHealth` | Check overall cluster health status | None |\n| **Basic Health** | `getServiceStatus` | Get status of specific Druid services | `serviceType` (String) |\n| **Basic Health** | `getClusterConfiguration` | Get cluster configuration information | None |\n| **Diagnostics** | `runDruidDoctor` | Run comprehensive cluster diagnostics | None |\n| **Diagnostics** | `analyzePerformanceIssues` | Analyze cluster performance issues | None |\n| **Diagnostics** | `generateHealthReport` | Generate detailed health report | None |\n| **Functionality** | `testQueryFunctionality` | Test query functionality across services | None |\n| **Functionality** | `testIngestionFunctionality` | Test ingestion functionality | None |\n| **Functionality** | `validateClusterConnectivity` | Validate connectivity between cluster components | None |\n\n## Available Resources by Feature\n\n| Feature | Resource URI Pattern | Description | Parameters |\n|---------|---------------------|-------------|------------|\n| **Datasource** | `druid://datasource/{datasourceName}` | Access datasource information and metadata | `datasourceName` (String) |\n| **Datasource** | `druid://datasource/{datasourceName}/details` | Access detailed datasource information including schema | `datasourceName` (String) |\n| **Lookup** | `druid://lookup/{tier}/{lookupName}` | Access lookup configuration and data | `tier` (String), `lookupName` (String) |\n| **Segments** | `druid://segment/{segmentId}` | Access segment metadata and information | `segmentId` (String) |\n\n## Available Prompts by Feature\n\n| Feature | Prompt Name | Description | Parameters |\n|---------|-------------|-------------|------------|\n| **Data Analysis** | `data-exploration` | Guide for exploring data in Druid datasources | `datasource` (String, optional) |\n| **Data Analysis** | `query-optimization` | Help optimize Druid SQL queries for better performance | `query` (String) |\n| **Cluster Management** | `health-check` | Comprehensive cluster health assessment guidance | None |\n| **Cluster Management** | `cluster-overview` | Overview and analysis of cluster status | None |\n| **Ingestion Management** | `ingestion-troubleshooting` | Troubleshoot ingestion issues | `issue` (String, optional) |\n| **Ingestion Management** | `ingestion-setup` | Guide for setting up new ingestion pipelines | `dataSource` (String, optional) |\n| **Retention Management** | `retention-management` | Manage data retention policies | `datasource` (String, optional) |\n| **Compaction** | `compaction-suggestions` | Optimize segment compaction configuration | `datasource` (String, optional), `currentConfig` (String, optional), `performanceMetrics` (String, optional) |\n| **Compaction** | `compaction-troubleshooting` | Troubleshoot compaction issues | `issue` (String), `datasource` (String, optional) |\n| **Operations** | `emergency-response` | Emergency response procedures and guidance | None |\n| **Operations** | `maintenance-mode` | Cluster maintenance procedures | None |\n\n## Configuration\n\nConfigure your Druid connection in `src/main/resources/application.properties`:\n\n```properties\n# Spring AI MCP Server configuration\nspring.ai.mcp.server.name=druid-mcp-server\nspring.ai.mcp.server.version=1.0.0\n\n# Druid configuration\ndruid.router.url=http://localhost:8888\n\n# Server configuration\nserver.port=8080\n\n# NOTE: Banner and console logging must be disabled for STDIO transport\nspring.main.banner-mode=off\n```\n\n### Environment Variables Configuration\n\nFor sensitive credentials like username and password, you can use environment variables instead of hardcoding them in properties files.\n\n#### Supported Environment Variables\n\n- `DRUID_AUTH_USERNAME`: Druid authentication username\n- `DRUID_AUTH_PASSWORD`: Druid authentication password  \n- `DRUID_ROUTER_URL`: Override the default Druid router URL\n- `DRUID_SSL_ENABLED`: Enable SSL/TLS support (true/false)\n- `DRUID_SSL_SKIP_VERIFICATION`: Skip SSL certificate verification (true/false)\n\n### SSL-Encrypted Cluster with Authentication\n\nThis section provides comprehensive guidance on connecting to SSL-encrypted Druid clusters with username and password authentication.\n\n#### Prerequisites\n\n- SSL-enabled Druid cluster with HTTPS endpoints\n- Valid username and password credentials for Druid authentication\n- SSL certificates properly configured (or ability to skip verification for testing)\n\n#### Configuration Methods\n\n##### Method 1: Environment Variables (Recommended for Production)\n\nSet the following environment variables before starting the MCP server:\n\n```bash\n# Druid cluster URL with HTTPS\nexport DRUID_ROUTER_URL=\"https://your-druid-cluster.example.com:8888\"\n\n# Authentication credentials\nexport DRUID_AUTH_USERNAME=\"your-username\"\nexport DRUID_AUTH_PASSWORD=\"your-password\"\n\n# SSL configuration\nexport DRUID_SSL_ENABLED=\"true\"\nexport DRUID_SSL_SKIP_VERIFICATION=\"false\"  # Use \"true\" only for testing\n\n# Start the MCP server\njava -jar target/druid-mcp-server-1.0.0.jar\n```\n\n##### Method 2: Application Properties\n\nUpdate `src/main/resources/application.properties`:\n\n```properties\n# Druid cluster configuration\ndruid.router.url=https://your-druid-cluster.example.com:8888\n\n# Authentication\ndruid.auth.username=your-username\ndruid.auth.password=your-password\n\n# SSL configuration\ndruid.ssl.enabled=true\ndruid.ssl.skip-verification=false\n```\n\n##### Method 3: Runtime System Properties\n\nPass configuration as JVM system properties:\n\n```bash\njava -Ddruid.router.url=\"https://your-druid-cluster.example.com:8888\" \\\n     -Ddruid.auth.username=\"your-username\" \\\n     -Ddruid.auth.password=\"your-password\" \\\n     -Ddruid.ssl.enabled=true \\\n     -Ddruid.ssl.skip-verification=false \\\n     -jar target/druid-mcp-server-1.0.0.jar\n```\n\n#### SSL Configuration Options\n\n##### Production SSL Setup\n\nFor production environments with valid SSL certificates:\n\n```bash\nexport DRUID_ROUTER_URL=\"https://druid-prod.company.com:8888\"\nexport DRUID_SSL_ENABLED=\"true\"\nexport DRUID_SSL_SKIP_VERIFICATION=\"false\"\n```\n\nThe server will use the system's default truststore to validate SSL certificates.\n\n##### Development/Testing SSL Setup\n\nFor development or testing with self-signed certificates:\n\n```bash\nexport DRUID_ROUTER_URL=\"https://druid-dev.local:8888\"\nexport DRUID_SSL_ENABLED=\"true\"\nexport DRUID_SSL_SKIP_VERIFICATION=\"true\"  # WARNING: Only for testing!\n```\n\n**‚ö†Ô∏è Security Warning**: Never use `DRUID_SSL_SKIP_VERIFICATION=true` in production environments as it disables SSL certificate validation.\n\n#### Authentication Methods\n\nThe MCP server supports HTTP Basic Authentication with username and password:\n\n- **Username**: Set via `DRUID_AUTH_USERNAME` or `druid.auth.username`\n- **Password**: Set via `DRUID_AUTH_PASSWORD` or `druid.auth.password`\n\nThe credentials are automatically encoded using Base64 and sent with each request using the `Authorization: Basic` header.\n\n#### Complete Example Configurations\n\n##### Example 1: Production Environment\n\n```bash\n#!/bin/bash\n# Production configuration script\n\n# Druid cluster settings\nexport DRUID_ROUTER_URL=\"https://druid.production.company.com:8888\"\n\n# Authentication\nexport DRUID_AUTH_USERNAME=\"druid-mcp-user\"\nexport DRUID_AUTH_PASSWORD=\"secure-password-123\"\n\n# SSL settings (production)\nexport DRUID_SSL_ENABLED=\"true\"\nexport DRUID_SSL_SKIP_VERIFICATION=\"false\"\n\n# Start MCP server\njava -jar target/druid-mcp-server-1.0.0.jar\n```\n\n##### Example 2: Development Environment\n\n```bash\n#!/bin/bash\n# Development configuration script\n\n# Local Druid cluster with self-signed certificates\nexport DRUID_ROUTER_URL=\"https://localhost:8888\"\n\n# Test credentials\nexport DRUID_AUTH_USERNAME=\"admin\"\nexport DRUID_AUTH_PASSWORD=\"admin123\"\n\n# SSL settings (development - skip verification)\nexport DRUID_SSL_ENABLED=\"true\"\nexport DRUID_SSL_SKIP_VERIFICATION=\"true\"\n\n# Start MCP server\njava -jar target/druid-mcp-server-1.0.0.jar\n```\n\n##### Example 3: MCP Client Configuration with SSL\n\nUpdate your `mcp-servers-config.json` to include environment variables:\n\n```json\n{\n  \"mcpServers\": {\n    \"druid-mcp-server\": {\n      \"command\": \"java\",\n      \"args\": [\n        \"-Dspring.ai.mcp.server.stdio=true\",\n        \"-Dspring.main.web-application-type=none\",\n        \"-Dlogging.pattern.console=\",\n        \"-jar\",\n        \"target/druid-mcp-server-1.0.0.jar\"\n      ],\n      \"env\": {\n        \"DRUID_ROUTER_URL\": \"https://your-druid-cluster.example.com:8888\",\n        \"DRUID_AUTH_USERNAME\": \"your-username\",\n        \"DRUID_AUTH_PASSWORD\": \"your-password\",\n        \"DRUID_SSL_ENABLED\": \"true\",\n        \"DRUID_SSL_SKIP_VERIFICATION\": \"false\"\n      }\n    }\n  }\n}\n```\n\n## MCP Prompt Customization\n\nThe server provides extensive prompt customization capabilities through the `prompts.properties` file located in `src/main/resources/`.\n\n### Prompt Configuration Structure\n\nThe prompts.properties file contains:\n\n1. **Global Settings**: Enable/disable prompts and set watermarks\n2. **Feature Toggles**: Control which prompts are available\n3. **Custom Variables**: Organization-specific information\n4. **Template Definitions**: Full prompt templates for each feature\n\n### Overriding Prompts\n\nYou can override any prompt template using Java system properties with the `-D` flag:\n\n#### Method 1: System Properties (Runtime Override)\n\n```bash\njava -Dprompts.druid-data-exploration.template=\"Your custom template here\" \\\n     -jar target/druid-mcp-server-1.0.0.jar\n```\n\n#### Method 2: Custom Properties File\n\n1. Create a custom properties file (e.g., `custom-prompts.properties`):\n```properties\n# Custom prompt template\nprompts.druid-data-exploration.template=My custom data exploration prompt:\\n\\\n1. Custom step one\\n\\\n2. Custom step two\\n\\\n{datasource_section}\\n\\\nEnvironment: {environment}\n```\n\n2. Load it at runtime:\n```bash\njava -Dspring.config.additional-location=classpath:custom-prompts.properties \\\n     -jar target/druid-mcp-server-1.0.0.jar\n```\n\n### Available Prompt Variables\n\nAll prompt templates support these variables:\n\n| Variable | Description | Example |\n|----------|-------------|---------|\n| `{environment}` | Current environment name | `production`, `staging`, `dev` |\n| `{organizationName}` | Organization name | `Your Organization` |\n| `{contactInfo}` | Contact information | `your-team@company.com` |\n| `{watermark}` | Generated watermark | `Generated by Druid MCP Server v1.0.0` |\n| `{datasource}` | Datasource name (context-specific) | `sales_data` |\n| `{query}` | SQL query (context-specific) | `SELECT * FROM sales_data` |\n\n### Prompt Template Examples\n\n#### Custom Data Exploration Prompt\n```properties\nprompts.druid-data-exploration.template=Welcome to {organizationName} Druid Analysis!\\n\\n\\\nPlease help me explore our data:\\n\\\n{datasource_section}\\n\\\nEnvironment: {environment}\\n\\\nContact: {contactInfo}\\n\\n\\\n{watermark}\n```\n\n#### Custom Query Optimization Prompt\n```properties\nprompts.druid-query-optimization.template=Query Performance Analysis for {organizationName}\\n\\n\\\nQuery to optimize: {query}\\n\\n\\\nPlease provide:\\n\\\n1. Performance bottleneck analysis\\n\\\n2. Optimization recommendations\\n\\\n3. Best practices for our {environment} environment\\n\\n\\\n{watermark}\n```\n\n### Disabling Specific Prompts\n\nYou can disable individual prompts by setting their enabled flag to false:\n\n```properties\nmcp.prompts.data-exploration.enabled=false\nmcp.prompts.query-optimization.enabled=false\n```\n\nOr disable all prompts globally:\n```properties\nmcp.prompts.enabled=false\n```\n\n## MCP Integration\n\nThis server uses Spring AI's MCP Server framework and supports both STDIO and SSE transports. The tools, resources, and prompts are automatically registered and exposed through the MCP protocol.\n\n### Transport Modes\n\n#### STDIO Transport (Recommended for LLM clients)\n```bash\njava -Dspring.ai.mcp.server.stdio=true \\\n     -Dspring.main.web-application-type=none \\\n     -Dlogging.pattern.console= \\\n     -jar target/druid-mcp-server-1.0.0.jar\n```\n\n#### SSE Transport (HTTP-based)\n```bash\njava -jar target/druid-mcp-server-1.0.0.jar\n# Server available at http://localhost:8080\n```\n\n### MCP Configuration for LLMs\n\nA ready-to-use MCP configuration file is provided at `mcp-servers-config.json` that can be used with LLM clients to connect to this Druid MCP server. \n\nThe configuration includes both transport options:\n\n#### STDIO Transport (Recommended)\nMore details on this on [examples/stdio/README.md](examples/stdio/README.md).\n\n```json\n{\n  \"mcpServers\": {\n    \"druid-mcp-server\": {\n      \"command\": \"java\",\n      \"args\": [\n        \"-Dspring.ai.mcp.server.stdio=true\",\n        \"-Dspring.main.web-application-type=none\",\n        \"-Dlogging.pattern.console=\",\n        \"-jar\",\n        \"target/druid-mcp-server-1.0.0.jar\"\n      ]\n    }\n  }\n}\n```\n\n#### SSE Transport\nMore details on this on [examples/sse/README.md](examples/stdio/README.md).\n\n```json\n{\n  \"mcpServers\": {\n    \"druid-mcp-server-sse\": {\n      \"url\": \"http://localhost:8080\"\n    }\n  }\n}\n```\n\n### Using with LLM Clients\n\n1. **Build the server first:** See [development.md](development.md) for build instructions\n2. **For STDIO transport:** The MCP server will be automatically started by the LLM client\n3. **For SSE transport:** Start the server manually first\n\n## Examples\n\nThis repository includes comprehensive examples to help you get started with different deployment scenarios and transport modes:\n\n### üê≥ [Druid Cluster Setup](examples/druidcluster/README.md)\nComplete Docker Compose configuration for running a full Apache Druid cluster locally. Perfect for development, testing, and learning about Druid cluster architecture.\n\n**Features:**\n- Full Druid cluster with all components (Coordinator, Broker, Historical, MiddleManager, Router)\n- PostgreSQL metadata storage and ZooKeeper coordination\n- Pre-configured with sample data and ingestion examples\n- Integrated Druid MCP Server for immediate testing\n\n### üì° [STDIO Transport Configuration](examples/stdio/README.md)\nConfiguration examples for STDIO (Standard Input/Output) transport mode - the recommended method for integrating with LLM clients like Claude Desktop.\n\n**Features:**\n- Development and production configuration templates\n- Authentication and SSL setup examples\n- Integration guides for popular MCP clients\n- Troubleshooting and security best practices\n\n### üê≥üì° [STDIO Transport with Docker](examples/stdio-docker/README.md)\nConfiguration examples for running the Druid MCP Server using Docker with STDIO transport mode. This approach combines the convenience of Docker deployment with STDIO transport for LLM client integration.\n\n**Features:**\n- Docker-based MCP configuration files for development and production\n- No Java installation required on client machines\n- Docker Compose setup for simplified deployment\n- Environment variable configuration for Druid connections\n- Authentication and SSL support via Docker environment variables\n\n### üåê [SSE Transport Configuration](examples/sse/README.md)\nConfiguration examples for SSE (Server-Sent Events) transport mode, providing HTTP-based communication suitable for web applications and REST API integrations.\n\n**Features:**\n- HTTP-based MCP server configuration\n- Custom port and production deployment examples\n- Web client integration patterns\n- Comparison with STDIO transport mode\n\n\n## Related Projects\n\nThis Druid MCP Server is part of a comprehensive ecosystem of Apache Druid tools and extensions developed by iunera. These complementary projects enhance different aspects of Druid cluster management and data ingestion:\n\n### üîß [Druid Cluster Configuration](https://github.com/iunera/druid-cluster-config)\nAdvanced configuration management and deployment tools for Apache Druid clusters. This project provides:\n\n- **Automated Cluster Setup**: Streamlined configuration templates for different deployment scenarios\n- **Configuration Management**: Best practices and templates for production Druid clusters\n- **Deployment Automation**: Tools and scripts for consistent cluster deployments\n- **Environment-Specific Configs**: Optimized configurations for development, staging, and production environments\n\n**Integration with Druid MCP Server**: The cluster configurations provided by this project work seamlessly with the monitoring and management capabilities of the Druid MCP Server, enabling comprehensive cluster lifecycle management.\n\n### üìä [Code Ingestion Druid Extension](https://github.com/iunera/iu-code-ingestion-druid-extension)\nA specialized Apache Druid extension for ingesting and analyzing code-related data and metrics. This extension enables:\n\n- **Code Metrics Ingestion**: Specialized parsers for code analysis data and software metrics\n- **Developer Analytics**: Tools for analyzing code quality, complexity, and development patterns\n- **CI/CD Integration**: Seamless integration with continuous integration and deployment pipelines\n- **Custom Data Formats**: Support for various code analysis tools and formats\n\n**Integration with Druid MCP Server**: This extension expands the ingestion capabilities that can be managed through the MCP server's ingestion management tools, providing specialized support for code analytics use cases.\n\n### Why Use These Together?\n\n- **Complete Ecosystem**: From cluster setup to specialized data ingestion and management\n- **Consistent Architecture**: All projects follow similar design principles and integration patterns\n- **Enhanced Capabilities**: Each project extends different aspects of the Druid ecosystem\n- **Production Ready**: Battle-tested configurations and extensions for enterprise deployments\n\n## Roadmap\n\n- **Readonly Mode**: Implement a Readonly Mode (R) for Druid and disallow the Create, Update, Delete on all tools.\n- **Authentication on SSE Mode**: Introduce Oauth Authentication\n- **Druid Auto Compaction**: Intelligent automatic compaction configuration\n- **MCP Auto Completion**: Enhanced autocomplete functionality with sampling\n- **Proper Observability**: Comprehensive metrics and tracing\n- **Enhanced Monitoring**: Advanced cluster monitoring and alerting capabilities\n- **Advanced Analytics**: Machine learning-powered insights and recommendations\n- **Security Enhancements**: Advanced authentication and authorization features\n- **Kubernetes Support**: Proper deployment on Kubernetes\n\n---\n\n## About iunera\n\nThis Druid MCP Server is developed and maintained by **[iunera](https://www.iunera.com)**, a leading provider of advanced AI and data analytics solutions. \n\niunera specializes in:\n- **AI-Powered Analytics**: Cutting-edge artificial intelligence solutions for data analysis\n- **Enterprise Data Platforms**: Scalable data infrastructure and analytics platforms (Druid, Flink, Kubernetes, Kafka, Spring)\n- **Model Context Protocol (MCP) Solutions**: Advanced MCP server implementations for various data systems\n- **Custom AI Development**: Tailored AI solutions for enterprise needs\n\nAs veterans in Apache Druid iunera deployed and maintained a large number of solutions based on [Apache Druid](https://druid.apache.org/) in productive enterprise grade scenarios. \n\nFor more information about our services and solutions, visit [www.iunera.com](https://www.iunera.com).\n\n### Contact & Support\n\nNeed help? Let \n\n- **Website**: [https://www.iunera.com](https://www.iunera.com)\n- **Professional Services**: Contact us through [www.iunera.com](https://www.iunera.com) or [email](mailto:contact@iunera.com?subject=Druid%20MCP%20Server%20inquiry) for enterprise support and custom development\n- **Open Source**: This project is open source and community contributions are welcome\n\n---\n\n*¬© 2024 [iunera](https://www.iunera.com). Licensed under the Apache License 2.0.*\n",
  "category": "Data",
  "quality_score": 73,
  "archestra_config": {
    "client_config_permutations": {
      "mcpServers": {
        "druid-mcp-server-jar-built": {
          "command": "java",
          "args": ["-jar", "target/druid-mcp-server-1.0.0.jar"],
          "env": {}
        },
        "druid-mcp-server-jar-downloaded": {
          "command": "java",
          "args": ["-jar", "druid-mcp-server-1.0.0.jar"],
          "env": {}
        },
        "druid-mcp-server-jar-downloaded-stdio": {
          "command": "java",
          "args": [
            "-Dspring.ai.mcp.server.stdio=true",
            "-Dspring.main.web-application-type=none",
            "-Dlogging.pattern.console=",
            "-jar",
            "druid-mcp-server-1.0.0.jar"
          ],
          "env": {}
        },
        "iunera-druid-mcp-server-docker": {
          "command": "docker",
          "args": [
            "run",
            "-p",
            "8080:8080",
            "-e",
            "DRUID_BROKER_URL=http://your-druid-broker:8082",
            "-e",
            "DRUID_COORDINATOR_URL=http://your-druid-coordinator:8081",
            "iunera/druid-mcp-server:latest"
          ],
          "env": {
            "DRUID_BROKER_URL": "http://your-druid-broker:8082",
            "DRUID_COORDINATOR_URL": "http://your-druid-coordinator:8081"
          }
        },
        "iunera-druid-mcp-server-docker-stdio": {
          "command": "docker",
          "args": [
            "run",
            "--rm",
            "-i",
            "-e",
            "SPRING_AI_MCP_SERVER_STDIO=true",
            "-e",
            "SPRING_MAIN_WEB_APPLICATION_TYPE=none",
            "-e",
            "LOGGING_PATTERN_CONSOLE=",
            "-e",
            "DRUID_BROKER_URL=http://your-druid-broker:8082",
            "-e",
            "DRUID_COORDINATOR_URL=http://your-druid-coordinator:8081",
            "iunera/druid-mcp-server:latest"
          ],
          "env": {
            "SPRING_AI_MCP_SERVER_STDIO": "true",
            "SPRING_MAIN_WEB_APPLICATION_TYPE": "none",
            "LOGGING_PATTERN_CONSOLE": "",
            "DRUID_BROKER_URL": "http://your-druid-broker:8082",
            "DRUID_COORDINATOR_URL": "http://your-druid-coordinator:8081"
          }
        }
      }
    },
    "oauth": {
      "provider": null,
      "required": false
    }
  },
  "github_info": {
    "owner": "iunera",
    "repo": "druid-mcp-server",
    "url": "https://github.com/iunera/druid-mcp-server",
    "name": "iunera__druid-mcp-server",
    "path": null,
    "stars": 5,
    "contributors": 2,
    "issues": 0,
    "releases": true,
    "ci_cd": true,
    "latest_commit_hash": "1c5ceca362353eb8b4d2fb34c905cb62932789d6"
  },
  "programming_language": "Java",
  "framework": null,
  "last_scraped_at": "2025-09-07T22:14:29.475Z",
  "evaluation_model": "gemini-2.5-flash",
  "protocol_features": {
    "implementing_tools": true,
    "implementing_prompts": true,
    "implementing_resources": true,
    "implementing_sampling": true,
    "implementing_roots": false,
    "implementing_logging": true,
    "implementing_stdio": true,
    "implementing_streamable_http": true,
    "implementing_oauth2": false
  },
  "dependencies": [
    {
      "name": "spring-boot",
      "importance": 10
    },
    {
      "name": "spring-ai-starter-mcp-server-webmvc",
      "importance": 10
    },
    {
      "name": "spring-ai-mcp-annotations",
      "importance": 9
    }
  ],
  "raw_dependencies": "=== pom.xml ===\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!--\n  ~ Copyright (C) 2025 Christian Schmitt, Tim Frey\n  ~\n  ~ Licensed under the Apache License, Version 2.0 (the \"License\");\n  ~ you may not use this file except in compliance with the License.\n  ~ You may obtain a copy of the License at\n  ~\n  ~      http://www.apache.org/licenses/LICENSE-2.0\n  ~\n  ~ Unless required by applicable law or agreed to in writing, software\n  ~ distributed under the License is distributed on an \"AS IS\" BASIS,\n  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n  ~ See the License for the specific language governing permissions and\n  ~ limitations under the License.\n  -->\n\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n    <parent>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-parent</artifactId>\n        <version>3.5.3</version>\n        <relativePath/> <!-- lookup parent from repository -->\n    </parent>\n    <groupId>com.iunera</groupId>\n    <artifactId>druid-mcp-server</artifactId>\n    <version>1.0.1</version>\n    <name>druid-mcp-server</name>\n    <description>A comprehensive Model Context Protocol (MCP) server for Apache Druid that provides AI-assisted tools, resources, and prompts for managing and analyzing Druid clusters. Built with Spring Boot and Spring AI, this server enables seamless integration between Large Language Models and Apache Druid through standardized MCP protocol, offering extensive data management, ingestion control, monitoring capabilities, and automated cluster operations for modern data analytics workflows. Developed by iunera (https://www.iunera.com).</description>\n    <url>https://github.com/iunera/druid-mcp-server</url>\n    <licenses>\n        <license>\n            <name>Apache License, Version 2.0</name>\n            <url>http://www.apache.org/licenses/LICENSE-2.0.txt</url>\n            <distribution>repo</distribution>\n        </license>\n    </licenses>\n    <organization>\n        <name>iunera GmbH + Co. KG.</name>\n        <url>https://www.iunera.com/</url>\n    </organization>\n\n    <developers>\n        <developer>\n            <name>Christian Schmitt</name>\n        </developer>\n        <developer>\n            <name>Tim Frey</name>\n        </developer>\n    </developers>\n\n    <scm>\n        <connection>scm:git:git://github.com/iunera/druid-mcp-server.git</connection>\n        <developerConnection>scm:git:ssh://github.com:iunera/druid-mcp-server.git</developerConnection>\n        <url>https://github.com/iunera/druid-mcp-server/</url>\n    </scm>\n\n    <properties>\n        <java.version>24</java.version>\n    </properties>\n\n    <dependencyManagement>\n        <dependencies>\n            <dependency>\n                <groupId>org.springframework.ai</groupId>\n                <artifactId>spring-ai-bom</artifactId>\n                <version>1.1.0-SNAPSHOT</version>\n                <type>pom</type>\n                <scope>import</scope>\n            </dependency>\n        </dependencies>\n    </dependencyManagement>\n\n    <dependencies>\n        <dependency>\n            <groupId>com.logaritex.mcp</groupId>\n            <artifactId>spring-ai-mcp-annotations</artifactId>\n            <version>0.1.0</version>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.ai</groupId>\n            <artifactId>spring-ai-starter-mcp-server-webmvc</artifactId>\n        </dependency>\n\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-test</artifactId>\n            <scope>test</scope>\n        </dependency>\n    </dependencies>\n\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.springframework.boot</groupId>\n                <artifactId>spring-boot-maven-plugin</artifactId>\n            </plugin>\n        </plugins>\n    </build>\n\n    <repositories>\n        <repository>\n            <id>spring-milestones</id>\n            <name>Spring Milestones</name>\n            <url>https://repo.spring.io/milestone</url>\n            <snapshots>\n                <enabled>false</enabled>\n            </snapshots>\n        </repository>\n        <repository>\n            <id>spring-snapshots</id>\n            <name>Spring Snapshots</name>\n            <url>https://repo.spring.io/snapshot</url>\n            <releases>\n                <enabled>false</enabled>\n            </releases>\n        </repository>\n        <repository>\n            <id>central-portal-snapshots</id>\n            <name>Central Portal Snapshots</name>\n            <url>https://central.sonatype.com/repository/maven-snapshots/</url>\n            <releases>\n                <enabled>false</enabled>\n            </releases>\n            <snapshots>\n                <enabled>true</enabled>\n            </snapshots>\n        </repository>\n    </repositories>\n\n    <profiles>\n        <profile>\n            <id>release</id>\n            <build>\n                <plugins>\n                    <plugin>\n                        <groupId>org.apache.maven.plugins</groupId>\n                        <artifactId>maven-source-plugin</artifactId>\n                        <executions>\n                            <execution>\n                                <id>attach-sources</id>\n                                <goals>\n                                    <goal>jar-no-fork</goal>\n                                </goals>\n                            </execution>\n                        </executions>\n                    </plugin>\n                    <plugin>\n                        <groupId>org.apache.maven.plugins</groupId>\n                        <artifactId>maven-javadoc-plugin</artifactId>\n                        <executions>\n                            <execution>\n                                <id>attach-javadocs</id>\n                                <goals>\n                                    <goal>jar</goal>\n                                </goals>\n                            </execution>\n                        </executions>\n                        <configuration>\n                            <doclint>none</doclint>\n                            <source>24</source>\n                        </configuration>\n                    </plugin>\n\n                    <plugin>\n                        <groupId>org.apache.maven.plugins</groupId>\n                        <artifactId>maven-gpg-plugin</artifactId>\n                        <executions>\n                            <execution>\n                                <id>sign-artifacts</id>\n                                <phase>verify</phase>\n                                <goals>\n                                    <goal>sign</goal>\n                                </goals>\n                            </execution>\n                        </executions>\n                    </plugin>\n                    <plugin>\n                        <groupId>org.sonatype.central</groupId>\n                        <artifactId>central-publishing-maven-plugin</artifactId>\n                        <version>0.8.0</version>\n                        <extensions>true</extensions>\n                        <configuration>\n                            <publishingServerId>central</publishingServerId>\n                            <autoPublish>false</autoPublish>\n                        </configuration>\n                    </plugin>\n\n                </plugins>\n            </build>\n        </profile>\n    </profiles>\n\n</project>\n"
}
