{
  "dxt_version": "0.1.0",
  "name": "g0t4__mcp-server-commands",
  "display_name": "mcp-server-commands",
  "version": "1.0.0",
  "description": "Model Context Protocol server to run commands",
  "author": {
    "name": "g0t4"
  },
  "server": {
    "command": "npx",
    "args": ["-y", "mcp-server-commands"],
    "env": {}
  },
  "tools": [],
  "prompts": [],
  "keywords": [],
  "user_config": {},
  "readme": "## Tools\n\nTools are for LLMs to request. Claude Sonnet 3.5 intelligently uses `run_command`. And, initial testing shows promising results with [Groq Desktop with MCP](https://github.com/groq/groq-desktop-beta) and `llama4` models.\n\nCurrently, just one command to rule them all!\n\n- `run_command` - run a command, i.e. `hostname` or `ls -al` or `echo \"hello world\"` etc\n  - Returns `STDOUT` and `STDERR` as text\n  - Optional `stdin` parameter means your LLM can\n    - pass code in `stdin` to commands like `fish`, `bash`, `zsh`, `python`\n    - create files with `cat >> foo/bar.txt` from the text in `stdin`\n\n> [!WARNING]\n> Be careful what you ask this server to run!\n> In Claude Desktop app, use `Approve Once` (not `Allow for This Chat`) so you can review each command, use `Deny` if you don't trust the command.\n> Permissions are dictated by the user that runs the server.\n> DO NOT run with `sudo`.\n\n## Video walkthrough\n\n<a href=\"https://youtu.be/0-VPu1Pc18w\"><img src=\"https://img.youtube.com/vi/0-VPu1Pc18w/maxresdefault.jpg\" width=\"480\" alt=\"YouTube Thumbnail\"></a>\n\n## Prompts\n\nPrompts are for users to include in chat history, i.e. via `Zed`'s slash commands (in its AI Chat panel)\n\n- `run_command` - generate a prompt message with the command output\n\n## Development\n\nInstall dependencies:\n```bash\nnpm install\n```\n\nBuild the server:\n```bash\nnpm run build\n```\n\nFor development with auto-rebuild:\n```bash\nnpm run watch\n```\n\n## Installation\n\nTo use with Claude Desktop, add the server config:\n\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\n\nGroq Desktop (beta, macOS) uses `~/Library/Application Support/groq-desktop-app/settings.json`\n\n### Use the published npm package\n\nPublished to npm as [mcp-server-commands](https://www.npmjs.com/package/mcp-server-commands) using this [workflow](https://github.com/g0t4/mcp-server-commands/actions)\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-server-commands\": {\n      \"command\": \"npx\",\n      \"args\": [\"mcp-server-commands\"]\n    }\n  }\n}\n```\n\n### Use a local build (repo checkout)\n\nMake sure to run `npm run build`\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-server-commands\": {\n      // works b/c of shebang in index.js\n      \"command\": \"/path/to/mcp-server-commands/build/index.js\"\n    }\n  }\n}\n```\n\n## Local Models\n\n- Most models are trained such that they don't think they can run commands for you.\n  - Sometimes, they use tools w/o hesitation... other times, I have to coax them.\n  - Use a system prompt or prompt template to instruct that they should follow user requests. Including to use `run_commands` without double checking.\n- Ollama is a great way to run a model locally (w/ Open-WebUI)\n\n```sh\n# NOTE: make sure to review variants and sizes, so the model fits in your VRAM to perform well!\n\n# Probably the best so far is [OpenHands LM](https://www.all-hands.dev/blog/introducing-openhands-lm-32b----a-strong-open-coding-agent-model)\nollama pull https://huggingface.co/lmstudio-community/openhands-lm-32b-v0.1-GGUF\n\n# https://ollama.com/library/devstral\nollama pull devstral\n\n# Qwen2.5-Coder has tool use but you have to coax it\nollama pull qwen2.5-coder\n```\n\n### HTTP / OpenAPI\n\nThe server is implemented with the `STDIO` transport.\nFor `HTTP`, use [`mcpo`](https://github.com/open-webui/mcpo) for an `OpenAPI` compatible web server interface.\nThis works with [`Open-WebUI`](https://github.com/open-webui/open-webui)\n\n```bash\nuvx mcpo --port 3010 --api-key \"supersecret\" -- npx mcp-server-commands\n\n# uvx runs mcpo => mcpo run npx => npx runs mcp-server-commands\n# then, mcpo bridges STDIO <=> HTTP\n```\n\n> [!WARNING]\n> I briefly used `mcpo` with `open-webui`, make sure to vet it for security concerns.\n\n### Logging\n\nClaude Desktop app writes logs to `~/Library/Logs/Claude/mcp-server-mcp-server-commands.log`\n\nBy default, only important messages are logged (i.e. errors).\nIf you want to see more messages, add `--verbose` to the `args` when configuring the server.\n\nBy the way, logs are written to `STDERR` because that is what Claude Desktop routes to the log files.\nIn the future, I expect well formatted log messages to be written over the `STDIO` transport to the MCP client (note: not Claude Desktop app).\n\n### Debugging\n\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\n\n```bash\nnpm run inspector\n```\n\nThe Inspector will provide a URL to access debugging tools in your browser.\n",
  "category": "Development",
  "quality_score": 64,
  "archestra_config": {
    "client_config_permutations": {
      "mcp-server-commands": {
        "command": "npx",
        "args": ["mcp-server-commands"],
        "env": {}
      },
      "mcp-server-commands-local-build": {
        "command": "/path/to/mcp-server-commands/build/index.js",
        "args": [],
        "env": {}
      },
      "mcp-server-commands-via-mcpo": {
        "command": "uvx",
        "args": ["mcpo", "--port", "3010", "--api-key", "supersecret", "--", "npx", "mcp-server-commands"],
        "env": {}
      },
      "mcp-server-commands-verbose": {
        "command": "npx",
        "args": ["mcp-server-commands", "--verbose"],
        "env": {}
      }
    },
    "oauth": {
      "provider": null,
      "required": false
    }
  },
  "github_info": {
    "owner": "g0t4",
    "repo": "mcp-server-commands",
    "url": "https://github.com/g0t4/mcp-server-commands",
    "name": "g0t4__mcp-server-commands",
    "path": null,
    "stars": 192,
    "contributors": 1,
    "issues": 0,
    "releases": true,
    "ci_cd": true,
    "latest_commit_hash": "4973cc443c6ccd9c9b0c42506ac640f342f0f76a"
  },
  "programming_language": "TypeScript",
  "framework": null,
  "last_scraped_at": "2025-09-09T13:05:21.169Z",
  "evaluation_model": "gemini-2.5-flash",
  "protocol_features": {
    "implementing_tools": true,
    "implementing_prompts": true,
    "implementing_resources": false,
    "implementing_sampling": false,
    "implementing_roots": false,
    "implementing_logging": true,
    "implementing_stdio": true,
    "implementing_streamable_http": false,
    "implementing_oauth2": false
  },
  "dependencies": [
    {
      "name": "@modelcontextprotocol/sdk",
      "importance": 10
    }
  ],
  "raw_dependencies": "=== package.json ===\n{\n    \"name\": \"mcp-server-commands\",\n    \"version\": \"0.5.0\",\n    \"description\": \"An MCP server to run arbitrary commands\",\n    \"private\": false,\n    \"type\": \"module\",\n    \"bin\": {\n        \"mcp-server-commands\": \"./build/index.js\"\n    },\n    \"files\": [\n        \"build\"\n    ],\n    \"scripts\": {\n        \"clean\": \"rm -rf build\",\n        \"build\": \"tsc && node -e \\\"require('fs').chmodSync('build/index.js', '755')\\\"\",\n        \"prepare\": \"npm run build\",\n        \"watch\": \"npm run build && tsc --watch\",\n        \"inspector\": \"npx @modelcontextprotocol/inspector build/index.js\",\n        \"test\": \"jest\",\n        \"test:watch\": \"jest --watch\",\n        \"test:integration\": \"jest tests/integration\"\n    },\n    \"dependencies\": {\n        \"@modelcontextprotocol/sdk\": \"1.9.0\"\n    },\n    \"devDependencies\": {\n        \"@types/jest\": \"^29.5.14\",\n        \"@types/node\": \"^22.14.1\",\n        \"jest\": \"^29.7.0\",\n        \"ts-jest\": \"^29.3.2\",\n        \"typescript\": \"^5.8.3\"\n    }\n}\n"
}
