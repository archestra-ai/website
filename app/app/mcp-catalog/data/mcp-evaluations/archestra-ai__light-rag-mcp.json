{
  "name": "archestra-ai__light-rag-mcp",
  "display_name": "LightRAG MCP Server",
  "description": "MCP server for LightRAG - a knowledge graph-enhanced RAG system. Supports Neo4j for graph storage, Qdrant for vector storage, and multiple LLM providers (OpenAI, Anthropic, Gemini).",
  "author": {
    "name": "archestra-ai"
  },
  "server": {
    "command": "docker",
    "args": [
      "run",
      "-i",
      "--rm",
      "-p",
      "8080:8080",
      "archestra/light-rag-mcp:latest"
    ],
    "env": {
      "LIGHTRAG_LLM_PROVIDER": "${user_config.llm_provider}",
      "LIGHTRAG_LLM_MODEL": "${user_config.llm_model}",
      "LIGHTRAG_LLM_API_KEY": "${user_config.llm_api_key}",
      "LIGHTRAG_EMBEDDING_PROVIDER": "${user_config.embedding_provider}",
      "LIGHTRAG_EMBEDDING_MODEL": "${user_config.embedding_model}",
      "LIGHTRAG_NEO4J_URI": "${user_config.neo4j_uri}",
      "LIGHTRAG_NEO4J_USERNAME": "${user_config.neo4j_username}",
      "LIGHTRAG_NEO4J_PASSWORD": "${user_config.neo4j_password}",
      "LIGHTRAG_QDRANT_URL": "${user_config.qdrant_url}",
      "LIGHTRAG_QDRANT_API_KEY": "${user_config.qdrant_api_key}"
    },
    "docker_image": "archestra/light-rag-mcp:latest",
    "type": "local"
  },
  "tools": [
    {
      "name": "query_document",
      "description": "Execute a semantic query against documents through LightRAG. Supports local, global, hybrid, naive, and mix query modes."
    },
    {
      "name": "insert_document",
      "description": "Insert text content directly into LightRAG storage. Extracts entities and relationships for the knowledge graph."
    },
    {
      "name": "insert_file",
      "description": "Insert a document from a file path into LightRAG storage."
    },
    {
      "name": "insert_batch",
      "description": "Insert a batch of documents from a directory."
    },
    {
      "name": "get_documents",
      "description": "Get list of all documents in the system."
    },
    {
      "name": "get_graph_labels",
      "description": "Get all entity types and relationship types from the knowledge graph."
    },
    {
      "name": "create_entities",
      "description": "Create multiple entities in the knowledge graph."
    },
    {
      "name": "create_relations",
      "description": "Create multiple relationships between entities in the knowledge graph."
    },
    {
      "name": "delete_by_entities",
      "description": "Delete entities from the knowledge graph by name."
    },
    {
      "name": "delete_by_doc_ids",
      "description": "Delete entities and relationships associated with specific documents."
    },
    {
      "name": "check_light-rag_health",
      "description": "Check LightRAG API and storage backend health."
    }
  ],
  "prompts": [],
  "keywords": [
    "rag",
    "knowledge-graph",
    "light-rag",
    "neo4j",
    "qdrant",
    "embeddings",
    "vector-database",
    "graph-database"
  ],
  "user_config": {
    "llm_provider": {
      "type": "string",
      "title": "LLM Provider",
      "description": "LLM provider to use: openai, anthropic, or gemini",
      "default": "openai",
      "required": false
    },
    "llm_model": {
      "type": "string",
      "title": "LLM Model",
      "description": "LLM model name (e.g., gpt-4o-mini, claude-sonnet-4-20250514, gemini-2.0-flash)",
      "default": "gpt-4o-mini",
      "required": false
    },
    "llm_api_key": {
      "type": "string",
      "title": "LLM API Key",
      "description": "API key for the LLM provider",
      "sensitive": true,
      "required": true
    },
    "embedding_provider": {
      "type": "string",
      "title": "Embedding Provider",
      "description": "Embedding provider to use: openai or gemini (Anthropic doesn't offer embeddings)",
      "default": "openai",
      "required": false
    },
    "embedding_model": {
      "type": "string",
      "title": "Embedding Model",
      "description": "Embedding model name",
      "default": "text-embedding-3-large",
      "required": false
    },
    "neo4j_uri": {
      "type": "string",
      "title": "Neo4j URI",
      "description": "Neo4j connection URI (e.g., bolt://localhost:7687). Leave empty to use local file storage.",
      "default": "",
      "required": false
    },
    "neo4j_username": {
      "type": "string",
      "title": "Neo4j Username",
      "description": "Neo4j username",
      "default": "neo4j",
      "required": false
    },
    "neo4j_password": {
      "type": "string",
      "title": "Neo4j Password",
      "description": "Neo4j password",
      "sensitive": true,
      "required": false
    },
    "qdrant_url": {
      "type": "string",
      "title": "Qdrant URL",
      "description": "Qdrant connection URL (e.g., http://localhost:6333). Leave empty to use local file storage.",
      "default": "",
      "required": false
    },
    "qdrant_api_key": {
      "type": "string",
      "title": "Qdrant API Key",
      "description": "Qdrant API key (required for Qdrant Cloud)",
      "sensitive": true,
      "required": false
    }
  },
  "readme": "# LightRAG MCP Server\n\nAn MCP server for [LightRAG](https://github.com/HKUDS/LightRAG) - a knowledge graph-enhanced Retrieval-Augmented Generation system.\n\n## Features\n\n- **Knowledge Graph RAG**: Combines vector search with knowledge graph for enhanced retrieval\n- **Multiple Query Modes**: local, global, hybrid, naive, and mix query strategies\n- **Entity & Relationship Management**: Create, edit, and delete entities and relationships\n- **Document Processing**: Insert documents with automatic entity extraction\n- **Multi-Provider Support**: OpenAI, Anthropic (Claude), and Google Gemini for LLM\n- **Flexible Storage**: Neo4j + Qdrant for production, or local files for development\n\n## Quick Start\n\n### Minimal (Local Storage)\n\n```bash\ndocker run -d -p 8080:8080 \\\n  -e LIGHTRAG_LLM_API_KEY=sk-xxx \\\n  -v light-rag-data:/app/data \\\n  archestra/light-rag-mcp:latest\n```\n\n### With Neo4j + Qdrant\n\n```bash\ndocker run -d -p 8080:8080 \\\n  -e LIGHTRAG_LLM_API_KEY=sk-xxx \\\n  -e LIGHTRAG_NEO4J_URI=bolt://neo4j:7687 \\\n  -e LIGHTRAG_NEO4J_PASSWORD=password \\\n  -e LIGHTRAG_QDRANT_URL=http://qdrant:6333 \\\n  archestra/light-rag-mcp:latest\n```\n\n### With Anthropic Claude\n\n```bash\ndocker run -d -p 8080:8080 \\\n  -e LIGHTRAG_LLM_PROVIDER=anthropic \\\n  -e LIGHTRAG_LLM_MODEL=claude-sonnet-4-20250514 \\\n  -e LIGHTRAG_LLM_API_KEY=sk-ant-xxx \\\n  -e LIGHTRAG_EMBEDDING_PROVIDER=openai \\\n  -e LIGHTRAG_EMBEDDING_API_KEY=sk-xxx \\\n  archestra/light-rag-mcp:latest\n```\n\n## Environment Variables\n\n| Variable | Default | Description |\n|----------|---------|-------------|\n| `LIGHTRAG_LLM_PROVIDER` | openai | LLM provider: openai, anthropic, gemini |\n| `LIGHTRAG_LLM_MODEL` | gpt-4o-mini | LLM model name |\n| `LIGHTRAG_LLM_API_KEY` | - | API key for LLM provider (required) |\n| `LIGHTRAG_EMBEDDING_PROVIDER` | openai | Embedding provider: openai, gemini |\n| `LIGHTRAG_EMBEDDING_MODEL` | text-embedding-3-large | Embedding model |\n| `LIGHTRAG_NEO4J_URI` | - | Neo4j URI (optional, uses local files if not set) |\n| `LIGHTRAG_NEO4J_PASSWORD` | - | Neo4j password |\n| `LIGHTRAG_QDRANT_URL` | - | Qdrant URL (optional, uses local files if not set) |\n\n## MCP Configuration\n\nConnect via streamable-http transport:\n\n```json\n{\n  \"mcpServers\": {\n    \"light-rag\": {\n      \"transport\": {\n        \"type\": \"streamableHttp\",\n        \"url\": \"http://localhost:8080/mcp\"\n      }\n    }\n  }\n}\n```\n\n## Available Tools\n\n- `query_document` - Semantic query with mode selection (local/global/hybrid/naive/mix)\n- `insert_document` - Insert text content with automatic entity extraction\n- `insert_file` - Insert from file path\n- `insert_batch` - Batch insert from directory\n- `get_documents` - List all documents\n- `get_graph_labels` - Get entity and relationship types\n- `create_entities` - Create new entities\n- `create_relations` - Create relationships\n- `delete_by_entities` - Delete by entity name\n- `delete_by_doc_ids` - Delete by document ID\n- `check_light-rag_health` - System health check\n",
  "category": "AI Tools",
  "quality_score": 70,
  "archestra_config": {
    "client_config_permutations": {
      "light-rag-mcp-docker": {
        "command": "docker",
        "args": [
          "run",
          "-i",
          "--rm",
          "-p",
          "8080:8080",
          "archestra/light-rag-mcp:latest"
        ],
        "env": {
          "LIGHTRAG_LLM_PROVIDER": "${user_config.llm_provider}",
          "LIGHTRAG_LLM_MODEL": "${user_config.llm_model}",
          "LIGHTRAG_LLM_API_KEY": "${user_config.llm_api_key}",
          "LIGHTRAG_EMBEDDING_PROVIDER": "${user_config.embedding_provider}",
          "LIGHTRAG_EMBEDDING_MODEL": "${user_config.embedding_model}",
          "LIGHTRAG_NEO4J_URI": "${user_config.neo4j_uri}",
          "LIGHTRAG_NEO4J_USERNAME": "${user_config.neo4j_username}",
          "LIGHTRAG_NEO4J_PASSWORD": "${user_config.neo4j_password}",
          "LIGHTRAG_QDRANT_URL": "${user_config.qdrant_url}",
          "LIGHTRAG_QDRANT_API_KEY": "${user_config.qdrant_api_key}"
        },
        "docker_image": "archestra/light-rag-mcp:latest"
      }
    },
    "oauth": {
      "provider": null,
      "required": false
    },
    "works_in_archestra": true
  },
  "github_info": {
    "owner": "archestra",
    "repo": "light-rag-mcp",
    "url": "https://github.com/archestra",
    "name": "light-rag-mcp",
    "path": null,
    "stars": 0,
    "contributors": 1,
    "issues": 0,
    "releases": false,
    "ci_cd": false,
    "latest_commit_hash": null
  },
  "programming_language": "Python",
  "framework": "FastMCP",
  "last_scraped_at": null,
  "evaluation_model": null,
  "protocol_features": {
    "implementing_tools": true,
    "implementing_prompts": false,
    "implementing_resources": false,
    "implementing_sampling": false,
    "implementing_roots": false,
    "implementing_logging": false,
    "implementing_stdio": true,
    "implementing_streamable_http": false,
    "implementing_oauth2": false
  },
  "dependencies": [
    {
      "name": "lightrag-hku",
      "importance": 10
    },
    {
      "name": "mcp",
      "importance": 10
    },
    {
      "name": "neo4j",
      "importance": 8
    },
    {
      "name": "qdrant-client",
      "importance": 8
    },
    {
      "name": "openai",
      "importance": 7
    },
    {
      "name": "anthropic",
      "importance": 7
    },
    {
      "name": "google-genai",
      "importance": 7
    }
  ],
  "raw_dependencies": null
}
