{
  "name": "locust",
  "slug": "qainsights__locust-mcp-server",
  "description": "A Model Context Protocol (MCP) server implementation for running Locust load tests. This server enables seamless integration of Locust load testing capabilities with AI-powered development environments.",
  "readme": "# üöÄ ‚ö°Ô∏è locust-mcp-server\n\nA Model Context Protocol (MCP) server implementation for running Locust load tests. This server enables seamless integration of Locust load testing capabilities with AI-powered development environments.\n\n## ‚ú® Features\n\n- Simple integration with Model Context Protocol framework\n- Support for headless and UI modes\n- Configurable test parameters (users, spawn rate, runtime)\n- Easy-to-use API for running Locust load tests\n- Real-time test execution output\n- HTTP/HTTPS protocol support out of the box\n- Custom task scenarios support\n\n![Locust-MCP-Server](./images/locust-mcp.png)\n\n## üîß Prerequisites\n\nBefore you begin, ensure you have the following installed:\n\n- Python 3.13 or higher\n- uv package manager ([Installation guide](https://github.com/astral-sh/uv))\n\n## üì¶ Installation\n\n1. Clone the repository:\n\n```bash\ngit clone https://github.com/qainsights/locust-mcp-server.git\n```\n\n2. Install the required dependencies:\n\n```bash\nuv pip install -r requirements.txt\n```\n\n3. Set up environment variables (optional):\n   Create a `.env` file in the project root:\n\n```bash\nLOCUST_HOST=http://localhost:8089  # Default host for your tests\nLOCUST_USERS=3                     # Default number of users\nLOCUST_SPAWN_RATE=1               # Default user spawn rate\nLOCUST_RUN_TIME=10s               # Default test duration\n```\n\n## üöÄ Getting Started\n\n1. Create a Locust test script (e.g., `hello.py`):\n\n```python\nfrom locust import HttpUser, task, between\n\nclass QuickstartUser(HttpUser):\n    wait_time = between(1, 5)\n\n    @task\n    def hello_world(self):\n        self.client.get(\"/hello\")\n        self.client.get(\"/world\")\n\n    @task(3)\n    def view_items(self):\n        for item_id in range(10):\n            self.client.get(f\"/item?id={item_id}\", name=\"/item\")\n            time.sleep(1)\n\n    def on_start(self):\n        self.client.post(\"/login\", json={\"username\":\"foo\", \"password\":\"bar\"})\n```\n\n2. Configure the MCP server using the below specs in your favorite MCP client (Claude Desktop, Cursor, Windsurf and more):\n\n```json\n{\n  \"mcpServers\": {\n    \"locust\": {\n      \"command\": \"/Users/naveenkumar/.local/bin/uv\",\n      \"args\": [\n        \"--directory\",\n        \"/Users/naveenkumar/Gits/locust-mcp-server\",\n        \"run\",\n        \"locust_server.py\"\n      ]\n    }\n  }\n}\n```\n\n3. Now ask the LLM to run the test e.g. `run locust test for hello.py`. The Locust MCP server will use the following tool to start the test:\n\n- `run_locust`: Run a test with configurable options for headless mode, host, runtime, users, and spawn rate\n\n## üìù API Reference\n\n### Run Locust Test\n\n```python\nrun_locust(\n    test_file: str,\n    headless: bool = True,\n    host: str = \"http://localhost:8089\",\n    runtime: str = \"10s\",\n    users: int = 3,\n    spawn_rate: int = 1\n)\n```\n\nParameters:\n\n- `test_file`: Path to your Locust test script\n- `headless`: Run in headless mode (True) or with UI (False)\n- `host`: Target host to load test\n- `runtime`: Test duration (e.g., \"30s\", \"1m\", \"5m\")\n- `users`: Number of concurrent users to simulate\n- `spawn_rate`: Rate at which users are spawned\n\n## ‚ú® Use Cases\n\n- LLM powered results analysis\n- Effective debugging with the help of LLM\n\n## ü§ù Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## üìÑ License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n",
  "category": null,
  "qualityScore": 68,
  "githubUrl": "https://github.com/QAInsights/locust-mcp-server",
  "programmingLanguage": "Python",
  "gitHubOrg": "QAInsights",
  "gitHubRepo": "locust-mcp-server",
  "repositoryPath": null,
  "gh_stars": 5,
  "gh_contributors": 1,
  "gh_issues": 0,
  "gh_releases": false,
  "gh_ci_cd": false,
  "gh_latest_commit_hash": "5be4f5452682ed5ae3e618756d8ff2daf865e527",
  "last_scraped_at": "2025-08-01T13:16:56.413Z",
  "implementing_tools": null,
  "implementing_prompts": null,
  "implementing_resources": null,
  "implementing_sampling": null,
  "implementing_roots": null,
  "implementing_logging": null,
  "implementing_stdio": null,
  "implementing_streamable_http": null,
  "implementing_oauth2": null
}