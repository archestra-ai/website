{
  "dxt_version": "0.1.0",
  "name": "flux159__mcp-server-kubernetes",
  "display_name": "mcp-server-kubernetes",
  "version": "1.0.0",
  "description": "MCP Server for kubernetes management commands",
  "author": {
    "name": "Flux159"
  },
  "server": {
    "command": "npx",
    "args": ["mcp-server-kubernetes"],
    "env": {
      "ALLOW_ONLY_NON_DESTRUCTIVE_TOOLS": "${user_config.allow_only_non_destructive_tools}"
    }
  },
  "tools": [],
  "prompts": [],
  "keywords": [],
  "user_config": {
    "allow_only_non_destructive_tools": {
      "type": "boolean",
      "title": "Allow Only Non-Destructive Tools",
      "description": "Run the server in a non-destructive mode that disables all destructive operations (delete pods, delete deployments, delete namespaces, etc.).",
      "default": false,
      "required": false
    }
  },
  "readme": "# MCP Server Kubernetes\n\n[![CI](https://github.com/Flux159/mcp-server-kubernetes/actions/workflows/ci.yml/badge.svg)](https://github.com/yourusername/mcp-server-kubernetes/actions/workflows/ci.yml)\n[![Language](https://img.shields.io/github/languages/top/Flux159/mcp-server-kubernetes)](https://github.com/yourusername/mcp-server-kubernetes)\n[![Bun](https://img.shields.io/badge/runtime-bun-orange)](https://bun.sh)\n[![Kubernetes](https://img.shields.io/badge/kubernetes-%23326ce5.svg?style=flat&logo=kubernetes&logoColor=white)](https://kubernetes.io/)\n[![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=flat&logo=docker&logoColor=white)](https://www.docker.com/)\n[![Stars](https://img.shields.io/github/stars/Flux159/mcp-server-kubernetes)](https://github.com/Flux159/mcp-server-kubernetes/stargazers)\n[![Issues](https://img.shields.io/github/issues/Flux159/mcp-server-kubernetes)](https://github.com/Flux159/mcp-server-kubernetes/issues)\n[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](https://github.com/Flux159/mcp-server-kubernetes/pulls)\n[![Last Commit](https://img.shields.io/github/last-commit/Flux159/mcp-server-kubernetes)](https://github.com/Flux159/mcp-server-kubernetes/commits/main)\n[![Trust Score](https://archestra.ai/mcp-catalog/api/badge/quality/Flux159/mcp-server-kubernetes)](https://archestra.ai/mcp-catalog/flux159__mcp-server-kubernetes)\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/Flux159/mcp-server-kubernetes)\n\nMCP Server that can connect to a Kubernetes cluster and manage it. Supports loading kubeconfig from multiple sources in priority order.\n\nhttps://github.com/user-attachments/assets/f25f8f4e-4d04-479b-9ae0-5dac452dd2ed\n\n<a href=\"https://glama.ai/mcp/servers/w71ieamqrt\"><img width=\"380\" height=\"200\" src=\"https://glama.ai/mcp/servers/w71ieamqrt/badge\" /></a>\n\n## Installation & Usage\n\n### Prerequisites\n\nBefore using this MCP server with any tool, make sure you have:\n\n1. kubectl installed and in your PATH\n2. A valid kubeconfig file with contexts configured\n3. Access to a Kubernetes cluster configured for kubectl (e.g. minikube, Rancher Desktop, GKE, etc.)\n4. Helm v3 installed and in your PATH (no Tiller required). Optional if you don't plan to use Helm.\n\nYou can verify your connection by running `kubectl get pods` in a terminal to ensure you can connect to your cluster without credential issues.\n\nBy default, the server loads kubeconfig from `~/.kube/config`. For additional authentication options (environment variables, custom paths, etc.), see [ADVANCED_README.md](ADVANCED_README.md).\n\n### Claude Code\n\nAdd the MCP server to Claude Code using the built-in command:\n\n```bash\nclaude mcp add kubernetes -- npx mcp-server-kubernetes\n```\n\nThis will automatically configure the server in your Claude Code MCP settings.\n\n### Claude Desktop\n\nAdd the following configuration to your Claude Desktop config file:\n\n```json\n{\n  \"mcpServers\": {\n    \"kubernetes\": {\n      \"command\": \"npx\",\n      \"args\": [\"mcp-server-kubernetes\"]\n    }\n  }\n}\n```\n\n### VS Code\n\n[![Install Kubernetes MCP in VS Code](https://img.shields.io/badge/Install%20Kubernetes%20MCP%20in%20VS%20Code-blue?logo=visualstudiocode)](vscode:mcp/install?%7B%22name%22%3A%20%22kubernetes%22%2C%20%22type%22%3A%20%22stdio%22%2C%20%22command%22%3A%20%22npx%22%2C%20%22args%22%3A%20%5B%22mcp-server-kubernetes%22%5D%7D)\n\nFor VS Code integration, you can use the MCP server with extensions that support the Model Context Protocol:\n\n1. Install a compatible MCP extension (such as Claude Dev or similar MCP clients)\n2. Configure the extension to use this server:\n\n```json\n{\n  \"mcpServers\": {\n    \"kubernetes\": {\n      \"command\": \"npx\",\n      \"args\": [\"mcp-server-kubernetes\"],\n      \"description\": \"Kubernetes cluster management and operations\"\n    }\n  }\n}\n```\n\n### Cursor\n\nCursor supports MCP servers through its AI integration. Add the server to your Cursor MCP configuration:\n\n```json\n{\n  \"mcpServers\": {\n    \"kubernetes\": {\n      \"command\": \"npx\",\n      \"args\": [\"mcp-server-kubernetes\"]\n    }\n  }\n}\n```\n\nThe server will automatically connect to your current kubectl context. You can verify the connection by asking the AI assistant to list your pods or create a test deployment.\n\n## Usage with mcp-chat\n\n[mcp-chat](https://github.com/Flux159/mcp-chat) is a CLI chat client for MCP servers. You can use it to interact with the Kubernetes server.\n\n```shell\nnpx mcp-chat --server \"npx mcp-server-kubernetes\"\n```\n\nAlternatively, pass it your existing Claude Desktop configuration file from above (Linux should pass the correct path to config):\n\nMac:\n\n```shell\nnpx mcp-chat --config \"~/Library/Application Support/Claude/claude_desktop_config.json\"\n```\n\nWindows:\n\n```shell\nnpx mcp-chat --config \"%APPDATA%\\Claude\\claude_desktop_config.json\"\n```\n\n## Features\n\n- [x] Connect to a Kubernetes cluster\n- [x] Unified kubectl API for managing resources\n  - Get or list resources with `kubectl_get`\n  - Describe resources with `kubectl_describe`\n  - List resources with `kubectl_get`\n  - Create resources with `kubectl_create`\n  - Apply YAML manifests with `kubectl_apply`\n  - Delete resources with `kubectl_delete`\n  - Get logs with `kubectl_logs`\n  - Manage kubectl contexts with `kubectl_context`\n  - Explain Kubernetes resources with `explain_resource`\n  - List API resources with `list_api_resources`\n  - Scale resources with `kubectl_scale`\n  - Update field(s) of a resource with `kubectl_patch`\n  - Manage deployment rollouts with `kubectl_rollout`\n  - Execute any kubectl command with `kubectl_generic`\n  - Verify connection with `ping`\n- [x] Advanced operations\n  - Scale deployments with `kubectl_scale` (replaces legacy `scale_deployment`)\n  - Port forward to pods and services with `port_forward`\n  - Run Helm operations\n    - Install, upgrade, and uninstall charts\n    - Support for custom values, repositories, and versions\n    - Template-based installation (`helm_template_apply`) to bypass authentication issues\n    - Template-based uninstallation (`helm_template_uninstall`) to bypass authentication issues\n  - Pod cleanup operations\n    - Clean up problematic pods (`cleanup_pods`) in states: Evicted, ContainerStatusUnknown, Completed, Error, ImagePullBackOff, CrashLoopBackOff\n  - Node management operations\n    - Cordoning, draining, and uncordoning nodes (`node_management`) for maintenance and scaling operations\n- [x] Troubleshooting Prompt (`k8s-diagnose`)\n  - Guides through a systematic Kubernetes troubleshooting flow for pods based on a keyword and optional namespace.\n- [x] Non-destructive mode for read and create/update-only access to clusters\n- [x] Secrets masking for security (masks sensitive data in `kubectl get secrets` commands, does not affect logs)\n\n## Prompts\n\nThe MCP Kubernetes server includes specialized prompts to assist with common diagnostic operations.\n\n### /k8s-diagnose Prompt\n\nThis prompt provides a systematic troubleshooting flow for Kubernetes pods. It accepts a `keyword` to identify relevant pods and an optional `namespace` to narrow the search.\nThe prompt's output will guide you through an autonomous troubleshooting flow, providing instructions for identifying issues, collecting evidence, and suggesting remediation steps.\n\n## Local Development\n\nMake sure that you have [bun installed](https://bun.sh/docs/installation). Clone the repo & install dependencies:\n\n```bash\ngit clone https://github.com/Flux159/mcp-server-kubernetes.git\ncd mcp-server-kubernetes\nbun install\n```\n\n### Development Workflow\n\n1. Start the server in development mode (watches for file changes):\n\n```bash\nbun run dev\n```\n\n2. Run unit tests:\n\n```bash\nbun run test\n```\n\n3. Build the project:\n\n```bash\nbun run build\n```\n\n4. Local Testing with [Inspector](https://github.com/modelcontextprotocol/inspector)\n\n```bash\nnpx @modelcontextprotocol/inspector node dist/index.js\n# Follow further instructions on terminal for Inspector link\n```\n\n5. Local testing with Claude Desktop\n\n```json\n{\n  \"mcpServers\": {\n    \"mcp-server-kubernetes\": {\n      \"command\": \"node\",\n      \"args\": [\"/path/to/your/mcp-server-kubernetes/dist/index.js\"]\n    }\n  }\n}\n```\n\n6. Local testing with [mcp-chat](https://github.com/Flux159/mcp-chat)\n\n```bash\nbun run chat\n```\n\n## Contributing\n\nSee the [CONTRIBUTING.md](CONTRIBUTING.md) file for details.\n\n## Advanced\n\n### Non-Destructive Mode\n\nYou can run the server in a non-destructive mode that disables all destructive operations (delete pods, delete deployments, delete namespaces, etc.):\n\n```shell\nALLOW_ONLY_NON_DESTRUCTIVE_TOOLS=true npx mcp-server-kubernetes\n```\n\nFor Claude Desktop configuration with non-destructive mode:\n\n```json\n{\n  \"mcpServers\": {\n    \"kubernetes-readonly\": {\n      \"command\": \"npx\",\n      \"args\": [\"mcp-server-kubernetes\"],\n      \"env\": {\n        \"ALLOW_ONLY_NON_DESTRUCTIVE_TOOLS\": \"true\"\n      }\n    }\n  }\n}\n```\n\n### Commands Available in Non-Destructive Mode\n\nAll read-only and resource creation/update operations remain available:\n\n- Resource Information: `kubectl_get`, `kubectl_describe`, `kubectl_logs`, `explain_resource`, `list_api_resources`\n- Resource Creation/Modification: `kubectl_apply`, `kubectl_create`, `kubectl_scale`, `kubectl_patch`, `kubectl_rollout`\n- Helm Operations: `install_helm_chart`, `upgrade_helm_chart`, `helm_template_apply`, `helm_template_uninstall`\n- Connectivity: `port_forward`, `stop_port_forward`\n- Context Management: `kubectl_context`\n\n### Commands Disabled in Non-Destructive Mode\n\nThe following destructive operations are disabled:\n\n- `kubectl_delete`: Deleting any Kubernetes resources\n- `uninstall_helm_chart`: Uninstalling Helm charts\n- `cleanup`: Cleanup of managed resources\n- `cleanup_pods`: Cleaning up problematic pods\n- `node_management`: Node management operations (can drain nodes)\n- `kubectl_generic`: General kubectl command access (may include destructive operations)\n\n### Helm Template Apply Tool\n\nThe `helm_template_apply` tool provides an alternative way to install Helm charts that bypasses authentication issues commonly encountered with certain Kubernetes configurations. This tool is particularly useful when you encounter errors like:\n\n```\nWARNING: Kubernetes configuration file is group-readable. This is insecure.\nError: INSTALLATION FAILED: Kubernetes cluster unreachable: exec plugin: invalid apiVersion \"client.authentication.k8s.io/v1alpha1\"\n```\n\nInstead of using `helm install` directly, this tool:\n\n1. Uses `helm template` to generate YAML manifests from the Helm chart\n2. Applies the generated YAML using `kubectl apply`\n3. Handles namespace creation and cleanup automatically\n\n#### Usage Example\n\n```json\n{\n  \"name\": \"helm_template_apply\",\n  \"arguments\": {\n    \"name\": \"events-exporter\",\n    \"chart\": \".\",\n    \"namespace\": \"kube-event-exporter\",\n    \"valuesFile\": \"values.yaml\",\n    \"createNamespace\": true\n  }\n}\n```\n\nThis is equivalent to running:\n\n```bash\nhelm template events-exporter . -f values.yaml > events-exporter.yaml\nkubectl create namespace kube-event-exporter\nkubectl apply -f events-exporter.yaml -n kube-event-exporter\n```\n\n#### Parameters\n\n- `name`: Release name for the Helm chart\n- `chart`: Chart name or path to chart directory\n- `repo`: Chart repository URL (optional if using local chart path)\n- `namespace`: Kubernetes namespace to deploy to\n- `values`: Chart values as an object (optional)\n- `valuesFile`: Path to values.yaml file (optional, alternative to values object)\n- `createNamespace`: Whether to create the namespace if it doesn't exist (default: true)\n\n### Pod Cleanup with Existing Tools\n\nPod cleanup can be achieved using the existing `kubectl_get` and `kubectl_delete` tools with field selectors. This approach leverages standard Kubernetes functionality without requiring dedicated cleanup tools.\n\n#### Identifying Problematic Pods\n\nUse `kubectl_get` with field selectors to identify pods in problematic states:\n\n**Get failed pods:**\n\n```json\n{\n  \"name\": \"kubectl_get\",\n  \"arguments\": {\n    \"resourceType\": \"pods\",\n    \"namespace\": \"default\",\n    \"fieldSelector\": \"status.phase=Failed\"\n  }\n}\n```\n\n**Get completed pods:**\n\n```json\n{\n  \"name\": \"kubectl_get\",\n  \"arguments\": {\n    \"resourceType\": \"pods\",\n    \"namespace\": \"default\",\n    \"fieldSelector\": \"status.phase=Succeeded\"\n  }\n}\n```\n\n**Get pods with specific conditions:**\n\n```json\n{\n  \"name\": \"kubectl_get\",\n  \"arguments\": {\n    \"resourceType\": \"pods\",\n    \"namespace\": \"default\",\n    \"fieldSelector\": \"status.conditions[?(@.type=='Ready')].status=False\"\n  }\n}\n```\n\n#### Deleting Problematic Pods\n\nUse `kubectl_delete` with field selectors to delete pods in problematic states:\n\n**Delete failed pods:**\n\n```json\n{\n  \"name\": \"kubectl_delete\",\n  \"arguments\": {\n    \"resourceType\": \"pods\",\n    \"namespace\": \"default\",\n    \"fieldSelector\": \"status.phase=Failed\",\n    \"force\": true,\n    \"gracePeriodSeconds\": 0\n  }\n}\n```\n\n**Delete completed pods:**\n\n```json\n{\n  \"name\": \"kubectl_delete\",\n  \"arguments\": {\n    \"resourceType\": \"pods\",\n    \"namespace\": \"default\",\n    \"fieldSelector\": \"status.phase=Succeeded\",\n    \"force\": true,\n    \"gracePeriodSeconds\": 0\n  }\n}\n```\n\n#### Workflow\n\n1. **First, identify problematic pods** using `kubectl_get` with appropriate field selectors\n2. **Review the list** of pods in the response\n3. **Delete the pods** using `kubectl_delete` with the same field selectors\n\n#### Available Field Selectors\n\n- `status.phase=Failed` - Pods that have failed\n- `status.phase=Succeeded` - Pods that have completed successfully\n- `status.phase=Pending` - Pods that are pending\n- `status.conditions[?(@.type=='Ready')].status=False` - Pods that are not ready\n\n#### Safety Features\n\n- **Field selectors**: Target specific pod states precisely\n- **Force deletion**: Use `force=true` and `gracePeriodSeconds=0` for immediate deletion\n- **Namespace isolation**: Target specific namespaces or use `allNamespaces=true`\n- **Standard kubectl**: Uses well-established Kubernetes patterns\n\n### Node Management Tool\n\nThe `node_management` tool provides comprehensive node management capabilities for Kubernetes clusters, including cordoning, draining, and uncordoning operations. This is essential for cluster maintenance, scaling, and troubleshooting.\n\n#### Operations Available\n\n- **`list`**: List all nodes with their status and schedulability\n- **`cordon`**: Mark a node as unschedulable (no new pods will be scheduled)\n- **`drain`**: Safely evict all pods from a node and mark it as unschedulable\n- **`uncordon`**: Mark a node as schedulable again\n\n#### Usage Examples\n\n**1. List all nodes:**\n\n```json\n{\n  \"name\": \"node_management\",\n  \"arguments\": {\n    \"operation\": \"list\"\n  }\n}\n```\n\n**2. Cordon a node (mark as unschedulable):**\n\n```json\n{\n  \"name\": \"node_management\",\n  \"arguments\": {\n    \"operation\": \"cordon\",\n    \"nodeName\": \"worker-node-1\"\n  }\n}\n```\n\n**3. Drain a node (dry run first):**\n\n```json\n{\n  \"name\": \"node_management\",\n  \"arguments\": {\n    \"operation\": \"drain\",\n    \"nodeName\": \"worker-node-1\",\n    \"dryRun\": true\n  }\n}\n```\n\n**4. Drain a node (with confirmation):**\n\n```json\n{\n  \"name\": \"node_management\",\n  \"arguments\": {\n    \"operation\": \"drain\",\n    \"nodeName\": \"worker-node-1\",\n    \"dryRun\": false,\n    \"confirmDrain\": true,\n    \"force\": true,\n    \"ignoreDaemonsets\": true,\n    \"timeout\": \"5m\"\n  }\n}\n```\n\n**5. Uncordon a node:**\n\n```json\n{\n  \"name\": \"node_management\",\n  \"arguments\": {\n    \"operation\": \"uncordon\",\n    \"nodeName\": \"worker-node-1\"\n  }\n}\n```\n\n#### Drain Operation Parameters\n\n- `force`: Force the operation even if there are pods not managed by controllers\n- `gracePeriod`: Period of time in seconds given to each pod to terminate gracefully\n- `deleteLocalData`: Delete local data even if emptyDir volumes are used\n- `ignoreDaemonsets`: Ignore DaemonSet-managed pods (default: true)\n- `timeout`: The length of time to wait before giving up (e.g., '5m', '1h')\n- `dryRun`: Show what would be done without actually doing it\n- `confirmDrain`: Explicit confirmation to drain the node (required for actual draining)\n\n#### Safety Features\n\n- **Dry run by default**: Drain operations default to dry run to show what would be done\n- **Explicit confirmation**: Drain operations require `confirmDrain=true` to proceed\n- **Status tracking**: Shows node status before and after operations\n- **Timeout protection**: Configurable timeouts to prevent hanging operations\n- **Graceful termination**: Configurable grace periods for pod termination\n\n#### Common Use Cases\n\n1. **Cluster Maintenance**: Cordon nodes before maintenance, drain them, perform maintenance, then uncordon\n2. **Node Scaling**: Drain nodes before removing them from the cluster\n3. **Troubleshooting**: Isolate problematic nodes by cordoning them\n4. **Resource Management**: Drain nodes to redistribute workload\n\nFor additional advanced features, see the [ADVANCED_README.md](ADVANCED_README.md).\n\n## Architecture\n\nSee this [DeepWiki link](https://deepwiki.com/Flux159/mcp-server-kubernetes) for a more indepth architecture overview created by Devin.\n\nThis section describes the high-level architecture of the MCP Kubernetes server.\n\n### Request Flow\n\nThe sequence diagram below illustrates how requests flow through the system:\n\n```mermaid\nsequenceDiagram\n    participant Client\n    participant Transport as Transport Layer\n    participant Server as MCP Server\n    participant Filter as Tool Filter\n    participant Handler as Request Handler\n    participant K8sManager as KubernetesManager\n    participant K8s as Kubernetes API\n\n    Note over Transport: StdioTransport or<br>SSE Transport\n\n    Client->>Transport: Send Request\n    Transport->>Server: Forward Request\n\n    alt Tools Request\n        Server->>Filter: Filter available tools\n        Note over Filter: Remove destructive tools<br>if in non-destructive mode\n        Filter->>Handler: Route to tools handler\n\n        alt kubectl operations\n            Handler->>K8sManager: Execute kubectl operation\n            K8sManager->>K8s: Make API call\n        else Helm operations\n            Handler->>K8sManager: Execute Helm operation\n            K8sManager->>K8s: Make API call\n        else Port Forward operations\n            Handler->>K8sManager: Set up port forwarding\n            K8sManager->>K8s: Make API call\n        end\n\n        K8s-->>K8sManager: Return result\n        K8sManager-->>Handler: Process response\n        Handler-->>Server: Return tool result\n    else Resource Request\n        Server->>Handler: Route to resource handler\n        Handler->>K8sManager: Get resource data\n        K8sManager->>K8s: Query API\n        K8s-->>K8sManager: Return data\n        K8sManager-->>Handler: Format response\n        Handler-->>Server: Return resource data\n    end\n\n    Server-->>Transport: Send Response\n    Transport-->>Client: Return Final Response\n```\n\nSee this [DeepWiki link](https://deepwiki.com/Flux159/mcp-server-kubernetes) for a more indepth architecture overview created by Devin.\n\n## Publishing new release\n\nGo to the [releases page](https://github.com/Flux159/mcp-server-kubernetes/releases), click on \"Draft New Release\", click \"Choose a tag\" and create a new tag by typing out a new version number using \"v{major}.{minor}.{patch}\" semver format. Then, write a release title \"Release v{major}.{minor}.{patch}\" and description / changelog if necessary and click \"Publish Release\".\n\nThis will create a new tag which will trigger a new release build via the cd.yml workflow. Once successful, the new release will be published to [npm](https://www.npmjs.com/package/mcp-server-kubernetes). Note that there is no need to update the package.json version manually, as the workflow will automatically update the version number in the package.json file & push a commit to main.\n\n## Not planned\n\nAdding clusters to kubectx.\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=Flux159/mcp-server-kubernetes&type=Date)](https://www.star-history.com/#Flux159/mcp-server-kubernetes&Date)\n\n## 🖊️ Cite\n\nIf you find this repo useful, please cite:\n\n```\n@software{Patel_MCP_Server_Kubernetes_2024,\nauthor = {Patel, Paras and Sonwalkar, Suyog},\nmonth = jul,\ntitle = {{MCP Server Kubernetes}},\nurl = {https://github.com/Flux159/mcp-server-kubernetes},\nversion = {2.5.0},\nyear = {2024}\n}\n```\n",
  "category": "AI Tools",
  "quality_score": 79,
  "archestra_config": {
    "client_config_permutations": {
      "mcp-server-kubernetes": {
        "command": "npx",
        "args": ["-y", "mcp-server-kubernetes"],
        "env": {}
      },
      "mcp-server-kubernetes-readonly": {
        "command": "npx",
        "args": ["-y", "mcp-server-kubernetes"],
        "env": {
          "ALLOW_ONLY_NON_DESTRUCTIVE_TOOLS": "true"
        }
      },
      "mcp-server-kubernetes-local": {
        "command": "node",
        "args": ["/path/to/your/mcp-server-kubernetes/dist/index.js"],
        "env": {}
      },
      "mcp-server-kubernetes-dev": {
        "command": "bun",
        "args": ["run", "dev"],
        "env": {}
      },
      "mcp-server-kubernetes-chat-dev": {
        "command": "bun",
        "args": ["run", "chat"],
        "env": {}
      }
    },
    "oauth": {
      "provider": null,
      "required": false
    }
  },
  "github_info": {
    "owner": "Flux159",
    "repo": "mcp-server-kubernetes",
    "url": "https://github.com/Flux159/mcp-server-kubernetes",
    "name": "flux159__mcp-server-kubernetes",
    "path": null,
    "stars": 1041,
    "contributors": 30,
    "issues": 0,
    "releases": true,
    "ci_cd": true,
    "latest_commit_hash": "c55b9fdb88c0eb7780d7d33c181858bff63a9a87"
  },
  "programming_language": "TypeScript",
  "framework": null,
  "last_scraped_at": "2025-09-07T22:12:29.306Z",
  "evaluation_model": "gemini-2.5-pro",
  "protocol_features": {
    "implementing_tools": true,
    "implementing_prompts": true,
    "implementing_resources": true,
    "implementing_sampling": false,
    "implementing_roots": false,
    "implementing_logging": false,
    "implementing_stdio": true,
    "implementing_streamable_http": false,
    "implementing_oauth2": false
  },
  "dependencies": [
    {
      "name": "@modelcontextprotocol/sdk",
      "importance": 10
    },
    {
      "name": "@kubernetes/client-node",
      "importance": 9
    },
    {
      "name": "express",
      "importance": 8
    },
    {
      "name": "zod",
      "importance": 7
    },
    {
      "name": "js-yaml",
      "importance": 6
    },
    {
      "name": "yaml",
      "importance": 6
    }
  ],
  "raw_dependencies": "=== package.json ===\n{\n  \"name\": \"mcp-server-kubernetes\",\n  \"version\": \"2.9.0\",\n  \"description\": \"MCP server for interacting with Kubernetes clusters via kubectl\",\n  \"license\": \"MIT\",\n  \"type\": \"module\",\n  \"author\": \"Flux159\",\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"https://github.com/Flux159/mcp-server-kubernetes\"\n  },\n  \"bin\": {\n    \"mcp-server-kubernetes\": \"dist/index.js\"\n  },\n  \"files\": [\n    \"dist\"\n  ],\n  \"scripts\": {\n    \"build\": \"tsc && shx chmod +x dist/*.js\",\n    \"builddxt\": \"node_modules/.bin/dxt pack\",\n    \"dev\": \"tsc --watch\",\n    \"start\": \"node dist/index.js\",\n    \"test\": \"vitest run\",\n    \"prepublishOnly\": \"npm run build\",\n    \"dockerbuild\": \"docker buildx build -t flux159/mcp-server-kubernetes --platform linux/amd64,linux/arm64 --push .\",\n    \"chat\": \"npx mcp-chat --server \\\"./dist/index.js\\\"\",\n    \"version:update\": \"node scripts/update-version.js\"\n  },\n  \"keywords\": [\n    \"mcp\",\n    \"kubernetes\",\n    \"claude\",\n    \"anthropic\",\n    \"kubectl\"\n  ],\n  \"engines\": {\n    \"node\": \">=18\"\n  },\n  \"dependencies\": {\n    \"@kubernetes/client-node\": \"1.3.0\",\n    \"@modelcontextprotocol/sdk\": \"1.17.0\",\n    \"express\": \"4.21.2\",\n    \"js-yaml\": \"4.1.0\",\n    \"yaml\": \"2.7.0\",\n    \"zod\": \"3.23.8\"\n  },\n  \"devDependencies\": {\n    \"@types/express\": \"5.0.1\",\n    \"@types/js-yaml\": \"4.0.9\",\n    \"@types/node\": \"22.9.3\",\n    \"shx\": \"0.3.4\",\n    \"typescript\": \"5.6.2\",\n    \"vitest\": \"2.1.9\",\n    \"@anthropic-ai/dxt\": \"0.1.0\"\n  }\n}\n"
}
